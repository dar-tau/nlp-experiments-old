{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "bert-vision.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfj6qUCzeQfA"
      },
      "source": [
        "## Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMUnskJ9eQfB"
      },
      "source": [
        "guy_folder = \"/content/\"\n",
        "cache_dir = guy_folder+\"/cache/transformer_cache\""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "NqAi8nT2eQfG",
        "outputId": "c6db2a59-a2e5-4c99-fe36-ad440a8bb23f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# %pip install matplotlib seaborn pandas tqdm tensorboard\n",
        "\n",
        "%cd {guy_folder}\n",
        "!mkdir cache\n",
        "!mkdir cache/transformer_cache\n",
        "# %pip install --no-cache-dir --upgrade torch torchvision\n",
        "#==1.4.0+cu100 torchvision== -f https://download.pytorch.org/whl/torch_stable.html\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "mkdir: cannot create directory ‘cache’: File exists\n",
            "mkdir: cannot create directory ‘cache/transformer_cache’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htC1bYBQfkz6",
        "outputId": "d7d9ce77-e81a-4c01-bdab-b0595f6a675f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%cd {guy_folder}/cache/\n",
        "!git clone https://github.com/huggingface/transformers.git\n",
        "%pip install ./transformers\n",
        "%pip install -U nlp\n",
        "\n",
        "%cd {guy_folder}\n",
        "\n",
        "## Not working!!!\n",
        "!setenv TRANSFORMERS_CACHE /vol/scratch/guy/cache/transformer_cache\n",
        "!setenv CUDA_VISIBLE_DEVICES 0"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/cache\n",
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 43860, done.\u001b[K\n",
            "remote: Total 43860 (delta 0), reused 0 (delta 0), pack-reused 43860\u001b[K\n",
            "Receiving objects: 100% (43860/43860), 31.63 MiB | 11.80 MiB/s, done.\n",
            "Resolving deltas: 100% (30420/30420), done.\n",
            "Processing ./transformers\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 2.7MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.8.1.rc2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/83/8b9fccb9e48eeb575ee19179e2bdde0ee9a1904f97de5f02d19016b8804f/tokenizers-0.8.1rc2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 16.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==3.2.0) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==3.2.0) (1.18.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==3.2.0) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==3.2.0) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==3.2.0) (20.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==3.2.0) (2019.12.20)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==3.2.0) (0.7)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 28.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.2.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.2.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.2.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.2.0) (2020.6.20)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.2.0) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.2.0) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.2.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.2.0) (0.16.0)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-3.2.0-cp36-none-any.whl size=1058986 sha256=26761964f9f482e31dcb1caed14cf0a5cd2d3accc925a1a4c3ae3dce42786abe\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-yfsph9iq/wheels/02/9b/9d/6253b37fb4f7d72b5eeaacbbc3116710b11f600803e913a13f\n",
            "Successfully built transformers\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=52446f6eef03dad304af66cbd990b4427347e949a692b3df613001d343829b19\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc2 transformers-3.2.0\n",
            "Collecting nlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/e3/bcdc59f3434b224040c1047769c47b82705feca2b89ebbc28311e3764782/nlp-0.4.0-py3-none-any.whl (1.7MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7MB 2.7MB/s \n",
            "\u001b[?25hCollecting xxhash\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/73/826b19f3594756cb1c6c23d2fbd8ca6a77a9cd3b650c9dec5acc85004c38/xxhash-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (242kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 16.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from nlp) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from nlp) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from nlp) (0.7)\n",
            "Requirement already satisfied, skipping upgrade: dill in /usr/local/lib/python3.6/dist-packages (from nlp) (0.3.2)\n",
            "Collecting pyarrow>=0.16.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/99/0a605f016121ca314d1469dc9069e4978395bc46fda40f73099d90ad3ba4/pyarrow-1.0.1-cp36-cp36m-manylinux2014_x86_64.whl (17.3MB)\n",
            "\u001b[K     |████████████████████████████████| 17.3MB 202kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.6/dist-packages (from nlp) (1.0.5)\n",
            "Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.6/dist-packages (from nlp) (3.0.12)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from nlp) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->nlp) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->nlp) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->nlp) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->nlp) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->nlp) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->nlp) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas->nlp) (1.15.0)\n",
            "Installing collected packages: xxhash, pyarrow, nlp\n",
            "  Found existing installation: pyarrow 0.14.1\n",
            "    Uninstalling pyarrow-0.14.1:\n",
            "      Successfully uninstalled pyarrow-0.14.1\n",
            "Successfully installed nlp-0.4.0 pyarrow-1.0.1 xxhash-2.0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pyarrow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "/bin/bash: setenv: command not found\n",
            "/bin/bash: setenv: command not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcmnUF0-eQfT"
      },
      "source": [
        "%%script false\n",
        "# After login in through firefox to ImageNet\n",
        "%cd {guy_folder}/data\n",
        "!wget http://www.image-net.org/archive/stanford/fall11_whole.tar\n",
        "# !tar -xvf "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhRzzS1eeQfZ"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets import ImageNet, ImageFolder, CIFAR10, CIFAR100\n",
        "from torchvision import transforms\n",
        "from transformers import AutoModel, AutoTokenizer"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sS-kATGqeQfc"
      },
      "source": [
        "\n",
        "class DummyLayer(nn.Module):\n",
        "  def __init__(self, *args, **kwargs):\n",
        "    super().__init__()\n",
        "    pass\n",
        "  def forward(self, x, *args, **kwargs):\n",
        "    return x\n",
        "\n",
        "class PlainBERT(nn.Module):\n",
        "    def __init__(self, n_tokens, min_layer = None):\n",
        "        super().__init__()\n",
        "        self.nLayers = 6\n",
        "        self.nHeads = 12\n",
        "        self.seqLen = 512\n",
        "\n",
        "\n",
        "        bert = AutoModel.from_pretrained('distilbert-base-uncased', cache_dir = cache_dir)\n",
        "        self.position_embeddings = nn.Parameter(torch.Tensor(bert.embeddings.position_embeddings(torch.arange(self.seqLen)).detach().numpy()))\n",
        "        if min_layer is None:\n",
        "          self.bert = bert.transformer\n",
        "        else:\n",
        "          raise NotImplementedError\n",
        "          bert_ = bert.transformer\n",
        "          for n, m in bert_.layer.named_children():\n",
        "            if int(n) < min_layer:\n",
        "              setattr(bert_.layer, n, DummyLayer())\n",
        "        \n",
        "          self.bert = bert_\n",
        "\n",
        "        self.bert.requires_grad_(False)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.bert.forward(x + self.position_embeddings, attn_mask = torch.ones(x.size(0), 512).to(x.device),\n",
        "                                head_mask = torch.ones(self.nLayers, x.size(0), self.nHeads, self.seqLen, self.seqLen).to(x.device))\n",
        "\n",
        "class BertVision(nn.Module):\n",
        "    def __init__(self,  n_classes, img_dim):\n",
        "        super().__init__()\n",
        "        self.with_classifier = True\n",
        "        self.n_tokens = np.prod(img_dim)\n",
        "        self.top = nn.Sequential(\n",
        "                                 nn.Conv2d(3, 32, 3, padding = 1 ),\n",
        "                                 nn.LeakyReLU(0.2),\n",
        "                                 nn.Conv2d(32, 100, 3, padding = 1),\n",
        "                                 nn.LeakyReLU(0.2),\n",
        "                                 nn.Conv2d(100, 200, 3, padding = 1),\n",
        "                                 nn.LeakyReLU(0.2),\n",
        "                                 nn.Conv2d(200, 768, 3, stride = (1, 2), padding = 1),\n",
        "                                 nn.LeakyReLU(0.2)\n",
        "                                )\n",
        "        \n",
        "        self.top.apply(self._init_top)\n",
        "        self.bert = PlainBERT(n_tokens = self.n_tokens)\n",
        "        self.fc = nn.Linear(768 * self.n_tokens//2, n_classes)\n",
        "        self.layer_norm = nn.LayerNorm((512,))\n",
        "\n",
        "    def toggleIntermediate(self):\n",
        "        self.with_classifier = !self.with_classifier\n",
        "    \n",
        "    \n",
        "    def _init_top(self, m):\n",
        "        if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
        "            nn.init.kaiming_uniform_(m.weight)\n",
        "            m.bias.data.fill_(0.01)\n",
        "        pass\n",
        "    def forward(self, x):\n",
        "        x = self.top(x)\n",
        "        x = x.view(x.size(0), x.size(1), -1)\n",
        "        x = x.transpose(1,2)\n",
        "        x = self.bert(x)\n",
        "        x = torch.stack(x).squeeze(0)\n",
        "        x = x.transpose(1,2).contiguous()\n",
        "#         x = self.layer_norm(x)\n",
        "#         x = torch.mean(x, dim = (-2,))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        if self.with_classifier:\n",
        "            x = self.fc(x)\n",
        "        return x.squeeze(1)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bl9FlRaKeQfg",
        "outputId": "53b84340-d415-4b13-e618-6f08ea002d07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "train_folder = \"{}/data/imagenet12/train\".format(guy_folder)\n",
        "\n",
        "train_ds = ImageFolder(train_folder,\n",
        "            transform = transforms.Compose([transforms.ToTensor()]))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-44a98d08d706>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m train_ds = ImageFolder(train_folder,\n\u001b[0;32m----> 4\u001b[0;31m             transform = transforms.Compose([transforms.ToTensor()]))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    206\u001b[0m                                           \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m                                           \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m                                           is_valid_file=is_valid_file)\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m     92\u001b[0m         super(DatasetFolder, self).__init__(root, transform=transform,\n\u001b[1;32m     93\u001b[0m                                             target_transform=target_transform)\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_find_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m_find_classes\u001b[0;34m(self, dir)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mNo\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0msubdirectory\u001b[0m \u001b[0mof\u001b[0m \u001b[0manother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \"\"\"\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mcls_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content//data/imagenet12/train'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "-Udifw4deQfn",
        "outputId": "2830458a-dd5d-480a-877c-3a748c25256a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "train_ds = CIFAR100(\"{}/data/cifar100\".format(guy_folder), download = True, transform=transforms.ToTensor())"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGklKPtDJTlU",
        "outputId": "dce20a79-82c8-40cb-ffcb-240711ec1757",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "test_ds = CIFAR100(\"{}/data/cifar100\".format(guy_folder), download = True, transform=transforms.ToTensor(), train = False)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCIlaDRueQft"
      },
      "source": [
        "device = 'cuda'\n",
        "model = BertVision(len(train_ds.classes), (32,32)).to(device)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3MFYU_SeQfx",
        "outputId": "6ca92447-29dd-476d-aa9c-5b8c2f49f926",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "from collections import defaultdict\n",
        "batch_size = 8\n",
        "total = int(len(train_ds)/batch_size )\n",
        "\n",
        "from tqdm import tqdm_notebook, tqdm\n",
        "class_rep = defaultdict(int)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr = 1e-6)\n",
        "train_dataloader = DataLoader(train_ds, batch_size = batch_size, shuffle = True)\n",
        "test_dataloader = DataLoader(test_ds, batch_size = batch_size, shuffle = True)\n",
        "pbar = tqdm(enumerate(train_dataloader), total = total, leave = True, position = 0)\n",
        "acc_sum = 0\n",
        "\n",
        "for i, (x,y) in pbar:\n",
        "    if i >= total:\n",
        "        break\n",
        "    model.eval()\n",
        "    x_test, y_test = next(iter(test_dataloader))\n",
        "    test_acc = ((model(x_test.to(device)).argmax(dim =  -1) == y_test.to(device)).sum()).item()/batch_size\n",
        "    model.train()\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    y = y.to(device)\n",
        "    yhat = model(x.to(device))\n",
        "    loss = criterion(yhat, y)\n",
        "    acc_sum += (yhat.argmax(dim =  -1) == y).sum()\n",
        "    class_rep[y[0].item()] += 1 # Incomplete\n",
        "    topk = np.where(np.argsort(yhat[0].cpu().detach().numpy()) == y[0].detach().cpu().numpy())[0][0] # TODO: Incomplete\n",
        "    \n",
        "    pbar.set_postfix_str(\"Loss: {:.2f} Test Acc: {:.2f} Acc: {:.2f} Top: {} Class: {}\".format(loss.item(),\n",
        "                                                                                               test_acc, \n",
        "                                                                             acc_sum.item()/float(batch_size * (i+1)), \n",
        "                                                                             topk, class_rep[y[0].item()]))\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  2%|▏         | 130/6250 [01:40<1:18:23,  1.30it/s, Loss: 3.45 Test Acc: 0.12 Acc: 0.11 Top: 89 Class: 2]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-76-e41b6e0ce3a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGK6AHdTv0zU"
      },
      "source": [
        "from torchvision.models import resnet101"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eGINEDd4smU"
      },
      "source": [
        "vision_model = resnet101(pretrained = True)\n",
        "vision_model.fc = nn.Linear(vision_model.fc.in_features, 100)\n",
        "vision_model.to(device);"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ul5_1EQo4ynl",
        "outputId": "6d8957e3-3276-4c16-9cd4-e8bc8a7c58f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "from collections import defaultdict\n",
        "batch_size = 32\n",
        "total = int(len(train_ds)/batch_size )\n",
        "\n",
        "from tqdm import tqdm_notebook, tqdm\n",
        "class_rep = defaultdict(int)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(vision_model.parameters(), lr = 1e-2)\n",
        "train_dataloader = DataLoader(train_ds, batch_size = batch_size, shuffle = True)\n",
        "pbar = tqdm(enumerate(train_dataloader), total = total, leave = True, position = 0)\n",
        "acc_sum = 0\n",
        "\n",
        "for i, (x,y) in pbar:\n",
        "    if i >= total:\n",
        "        break\n",
        "    optimizer.zero_grad()\n",
        "    y = y.to(device)\n",
        "    # x = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "    #         std=[0.229, 0.224, 0.225],)(x)\n",
        "    yhat = vision_model(x.to(device))\n",
        "    loss = criterion(yhat, y)\n",
        "    acc_sum += (yhat.argmax(dim =  -1) == y).sum()\n",
        "    class_rep[y[0].item()] += 1 # Incomplete\n",
        "    topk = np.where(np.argsort(yhat[0].cpu().detach().numpy()) == y[0].detach().cpu().numpy())[0][0] # TODO: Incomplete\n",
        "    pbar.set_postfix_str(\"Loss: {:.2f} Acc: {:.2f} Top: {} Class: {}\".format(loss.item(), \n",
        "                                                                            acc_sum.item()/float(batch_size * (i+1)), \n",
        "                                                                            topk, class_rep[y[0].item()]))\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 1561/1562 [02:02<00:00, 12.76it/s, Loss: 3.81 Acc: 0.07 Top: 93 Class: 12]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIGjSx-t9sPR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iOzYWVLeQf1"
      },
      "source": [
        "y  = []\n",
        "z = []\n",
        "for x, _  in tqdm(train_ds):\n",
        "    z.append(x)\n",
        "    y.append((model(x.to(device).unsqueeze(0))).detach())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-3XJcm1eQf5"
      },
      "source": [
        "y = torch.stack(y)\n",
        "z = torch.stack(z)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FqeYGjteQf9",
        "outputId": "825df2ce-a86d-427c-cbf8-afe92780eddb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "z.std()/y.std()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1882, device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQ5EySnveQgC",
        "outputId": "7e4ffaff-cf1a-4991-b926-c1169165c162",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        }
      },
      "source": [
        "i = np.random.choice(len(train_ds))\n",
        "print(F.softmax(model(train_ds[i][0].unsqueeze(0).to(device))))\n",
        "print(model(train_ds[i][0].unsqueeze(0).to(device)).argmax())\n",
        "print(train_ds[i][1])\n",
        "t = transforms.Compose([\n",
        "#     transforms.Grayscale(),\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Grayscale(3),\n",
        "    transforms.ToTensor(),\n",
        "    \n",
        "    ])(train_ds[i][0])\n",
        "print(F.softmax(model(t.unsqueeze(0).to(device))))\n",
        "print(model(t.unsqueeze(0).to(device)).argmax())\n",
        "\n",
        "print(F.softmax(model(((train_ds[i+1][0])).unsqueeze(0).to(device))))\n",
        "print(F.softmax(model(((train_ds[i+1][0])).unsqueeze(0).to(device))).argmax())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.0692, 0.0424, 0.1471, 0.1713, 0.0508, 0.0646, 0.0176, 0.1053, 0.2545,\n",
            "         0.0771]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
            "tensor(8, device='cuda:0')\n",
            "5\n",
            "tensor([[0.0369, 0.0232, 0.1556, 0.2595, 0.0591, 0.1124, 0.0279, 0.1635, 0.1121,\n",
            "         0.0498]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
            "tensor(3, device='cuda:0')\n",
            "tensor([[0.0253, 0.0126, 0.1966, 0.1578, 0.0755, 0.1262, 0.0523, 0.2717, 0.0489,\n",
            "         0.0330]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
            "tensor(7, device='cuda:0')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  app.launch_new_instance()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncJnwGykeQgH",
        "outputId": "958cae92-1508-456e-f2ac-2cb9872fc7a6"
      },
      "source": [
        "model.load_state_dict(state_dict,strict = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_IncompatibleKeys(missing_keys=[], unexpected_keys=['fc.weight', 'fc.bias'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 661
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPjRCbmAeQgL",
        "outputId": "b8b8f345-257b-404d-b4b7-a8d214e1329b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "model.toggleIntermediate()\n",
        "i = np.random.choice(len(train_ds))\n",
        "a1 = (F.softmax(model(train_ds[i][0].unsqueeze(0).to(device))))\n",
        "\n",
        "t = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Grayscale(3),\n",
        "#     transforms.ColorJitter(10,10, 10),\n",
        "#     transforms.RandomRotation(90),\n",
        "    transforms.ToTensor(),\n",
        "    \n",
        "    ])(train_ds[i][0])\n",
        "a2 = (F.softmax(model(t.unsqueeze(0).to(device))))\n",
        "\n",
        "a3 = (F.softmax(model(((train_ds[i+1][0])).to(device).unsqueeze(0))))\n",
        "\n",
        "\n",
        "print(torch.norm(a1-a2, p = 2))\n",
        "print(torch.norm(a1-a3, p = 2))\n",
        "print(torch.norm(a2-a3, p = 2))\n",
        "model.toggleIntermediate()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.1502, device='cuda:0', grad_fn=<NormBackward0>)\n",
            "tensor(0.3791, device='cuda:0', grad_fn=<NormBackward0>)\n",
            "tensor(0.3801, device='cuda:0', grad_fn=<NormBackward0>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHFZLW3neQgO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}