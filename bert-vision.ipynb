{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "bert-vision.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfj6qUCzeQfA"
      },
      "source": [
        "## Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMUnskJ9eQfB"
      },
      "source": [
        "storageName = 'university'\n",
        "\n",
        "if storageName == 'paperspace': \n",
        "    guy_folder = \"/notebooks/\"\n",
        "elif storageName == 'colab':\n",
        "    guy_folder = \"/content/\"\n",
        "elif storageName == 'university':\n",
        "    guy_folder = '/vol/scratch/guy/'\n",
        "    \n",
        "    \n",
        "cache_dir = guy_folder+\"/cache/transformer_cache\""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3z5yhLLlzFk"
      },
      "source": [
        "%pip uninstall -y enum34"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqAi8nT2eQfG",
        "outputId": "9e576ad8-b5b3-44de-93e6-dbd835dafc38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# %pip install matplotlib seaborn pandas tqdm tensorboard\n",
        "\n",
        "%cd {guy_folder}\n",
        "!mkdir cache\n",
        "!mkdir cache/transformer_cache\n",
        "# %pip install --no-cache-dir --upgrade torch torchvision\n",
        "#==1.4.0+cu100 torchvision== -f https://download.pytorch.org/whl/torch_stable.html\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "htC1bYBQfkz6",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "source": [
        "%pip install wandb\n",
        "%cd {guy_folder}/cache/\n",
        "!git clone https://github.com/huggingface/transformers.git\n",
        "%pip install ./transformers\n",
        "%pip install -U nlp\n",
        "\n",
        "%cd {guy_folder}\n",
        "\n",
        "## Not working!!!\n",
        "!setenv TRANSFORMERS_CACHE /vol/scratch/guy/cache/transformer_cache\n",
        "!setenv CUDA_VISIBLE_DEVICES 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KPmqdmNj6dN"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhRzzS1eeQfZ",
        "outputId": "96e9574c-b6a9-4520-9292-9157da8c175a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets import ImageNet, ImageFolder, CIFAR10, CIFAR100\n",
        "from torchvision import transforms\n",
        "from torchvision.models import resnet101\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from transformers import AdamW\n",
        "import wandb"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wks3jN_niRZ7"
      },
      "source": [
        "# Sweep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mo6pVi-alzI9",
        "outputId": "fd6879bd-4068-4d3d-cc29-b14c452fa5d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "%%writefile bert-vision.py\n",
        "paperspace = True\n",
        "guy_folder = \"/content/\"\n",
        "if paperspace: \n",
        "    guy_folder = \"/notebooks/\"\n",
        "\n",
        "cache_dir = guy_folder+\"/cache/transformer_cache\"\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets import ImageNet, ImageFolder, CIFAR10, CIFAR100\n",
        "from torchvision import transforms\n",
        "from torchvision.models import resnet101, resnet50\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from transformers import AdamW\n",
        "import wandb\n",
        "\n",
        "\n",
        "class DummyLayer(nn.Module):\n",
        "  def __init__(self, *args, **kwargs):\n",
        "    super().__init__()\n",
        "    pass\n",
        "  def forward(self, x, *args, **kwargs):\n",
        "    return x\n",
        "\n",
        "class PlainBERT(nn.Module):\n",
        "    def __init__(self, n_tokens, min_layer = None):\n",
        "        super().__init__()\n",
        "        self.nLayers = 6\n",
        "        self.nHeads = 12\n",
        "        self.seqLen = 512\n",
        "\n",
        "\n",
        "        bert = AutoModel.from_pretrained('distilbert-base-uncased', cache_dir = cache_dir)\n",
        "        self.position_embeddings = nn.Parameter(\n",
        "            torch.Tensor(bert.embeddings.position_embeddings(torch.arange(self.seqLen)).detach().numpy()))\n",
        "        if min_layer is None:\n",
        "          self.bert = bert.transformer\n",
        "        else:\n",
        "          raise NotImplementedError\n",
        "          bert_ = bert.transformer\n",
        "          for n, m in bert_.layer.named_children():\n",
        "            if int(n) < min_layer:\n",
        "              setattr(bert_.layer, n, DummyLayer())\n",
        "        \n",
        "          self.bert = bert_\n",
        "\n",
        "        self.bert.requires_grad_(False)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.bert.forward(x + self.position_embeddings, attn_mask = torch.ones(x.size(0), 512).to(x.device),\n",
        "                                head_mask = torch.ones(self.nLayers, x.size(0), \n",
        "                                                       self.nHeads, self.seqLen, self.seqLen).to(x.device))\n",
        "\n",
        "class BertVision(nn.Module):\n",
        "    def __init__(self,  n_classes, img_dim):\n",
        "        super().__init__()\n",
        "        self.with_classifier = True\n",
        "        self.n_tokens = np.prod(img_dim)\n",
        "        self.top = nn.Sequential(\n",
        "                                 nn.Conv2d(3, 32, 3, padding = 1 ),\n",
        "                                 nn.LeakyReLU(0.2),\n",
        "                                 nn.Conv2d(32, 100, 3, padding = 1),\n",
        "                                 nn.LeakyReLU(0.2),\n",
        "                                 nn.Conv2d(100, 200, 3, padding = 1),\n",
        "                                 nn.LeakyReLU(0.2),\n",
        "                                 nn.Conv2d(200, 768, 3, stride = (1, 2), padding = 1),\n",
        "                                 nn.LeakyReLU(0.2)\n",
        "                                )\n",
        "        \n",
        "        self.top.apply(self._init_top)\n",
        "        self.bert = PlainBERT(n_tokens = self.n_tokens)\n",
        "        self.fc = nn.Linear(768 * self.n_tokens//2, n_classes)\n",
        "        self.layer_norm = nn.LayerNorm((512,))\n",
        "\n",
        "    def toggleIntermediate(self):\n",
        "        self.with_classifier = not self.with_classifier\n",
        "    \n",
        "    \n",
        "    def _init_top(self, m):\n",
        "        if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
        "            nn.init.kaiming_uniform_(m.weight)\n",
        "            m.bias.data.fill_(0.01)\n",
        "        pass\n",
        "    def forward(self, x):\n",
        "        x = self.top(x)\n",
        "        x = x.view(x.size(0), x.size(1), -1)\n",
        "        x = x.transpose(1,2)\n",
        "        x = self.bert(x)\n",
        "        x = torch.stack(x).squeeze(0)\n",
        "        x = x.transpose(1,2).contiguous()\n",
        "#         x = self.layer_norm(x)\n",
        "#         x = torch.mean(x, dim = (-2,))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        if self.with_classifier:\n",
        "            x = self.fc(x)\n",
        "        return x.squeeze(1)\n",
        "    \n",
        "    \n",
        "    \n",
        "device = 'cuda'\n",
        "train_ds = CIFAR100(\"{}/data/cifar100\".format(guy_folder), download = True, transform=transforms.ToTensor())\n",
        "test_ds = CIFAR100(\"{}/data/cifar100\".format(guy_folder), download = True, transform=transforms.ToTensor(), train = False)\n",
        "\n",
        "\n",
        "batch_size = 8\n",
        "\n",
        "lr = {'bert-vision': [1e-6, 5e-6, 1e-5, 5e-5],\n",
        "      'resnet': [3e-4, 1e-3, 3e-3, 1e-4]\n",
        "      }\n",
        "\n",
        "optimizerDict = {'adam': torch.optim.Adam,\n",
        "                 'adamw': AdamW,\n",
        "                 'sgd': torch.optim.SGD, # No momentum\n",
        "                 }\n",
        "\n",
        "def makeModel(modelName):\n",
        "  if modelName == 'resnet':\n",
        "    model_resnet = resnet50(pretrained = True)\n",
        "    model_resnet.fc = nn.Linear(model_resnet.fc.in_features, 100)\n",
        "    model_resnet.to(device)\n",
        "    model = model_resnet\n",
        "  elif modelName == 'bert-vision':\n",
        "    model = BertVision(len(train_ds.classes), (32,32)).to(device)\n",
        "  else:\n",
        "    model = Sequential()\n",
        "  return model\n",
        "\n",
        "def train(config):\n",
        "  \n",
        "  optimizerAlg = optimizerDict[config.optimizer]\n",
        "  if config.model == 'bert-vision': \n",
        "    if config.optimizer == 'adam':\n",
        "      optimizerAlg = optimizerDict['adamw']\n",
        "    if config.optimizer == 'sgd':\n",
        "      return\n",
        "  modelName = config.model\n",
        "  lr_idx = config.lr_idx\n",
        "  model = makeModel(modelName)\n",
        "\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = optimizerAlg(model.parameters(), lr = lr[modelName][lr_idx])\n",
        "  train_dataloader = DataLoader(train_ds, batch_size = batch_size, shuffle = True)\n",
        "  test_dataloader = DataLoader(test_ds, batch_size = batch_size, shuffle = True)\n",
        "  pbar = tqdm(train_dataloader, leave = True, position = 0)\n",
        "  acc_sum = 0\n",
        "\n",
        "  for i, (x,y) in enumerate(pbar):\n",
        "      model.train()    \n",
        "      optimizer.zero_grad()\n",
        "      y = y.to(device)\n",
        "      yhat = model(x.to(device))\n",
        "      loss = criterion(yhat, y)\n",
        "      acc_sum += (yhat.argmax(dim =  -1) == y).sum()    \n",
        "      wandb.log({'loss': loss.item(), \n",
        "                 'acc': acc_sum.item() / (batch_size * (i+1))})\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "wandb.init()\n",
        "config = wandb.config\n",
        "train(config)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting bert-vision.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJA22phbj1S6",
        "outputId": "5bc66f54-cfb5-4069-cf15-b95437b88373",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "config = {\n",
        "    'method': 'grid',\n",
        "    'program': 'bert-vision.py',\n",
        "    'parameters': \n",
        "    {\n",
        "        'lr_idx': {'values': [0, 1, 2, 3]},\n",
        "        'optimizer':{'values': ['adam', 'sgd']},\n",
        "        'model': {'values': ['resnet', 'bert-vision']}\n",
        "    }\n",
        "}\n",
        "sweep_id = wandb.sweep(config, project = 'bert-vision')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Create sweep with ID: ti2qxgh0\n",
            "Sweep URL: https://wandb.ai/dar-tau/bert-vision/sweeps/ti2qxgh0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fU3OwHktlzJR",
        "outputId": "f93b5260-02d0-4bf4-fa20-a9320748ed3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "assert(sweep_id.isalnum())\n",
        "!wandb agent {sweep_id}"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Starting wandb agent 🕵️\n",
            "2020-09-27 18:32:32,444 - wandb.wandb_agent - INFO - Running runs: []\n",
            "2020-09-27 18:32:47,832 - wandb.wandb_agent - INFO - Agent received command: run\n",
            "2020-09-27 18:32:47,832 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
            "\tlr_idx: 1\n",
            "\tmodel: bert-vision\n",
            "\toptimizer: adam\n",
            "2020-09-27 18:32:47,833 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python bert-vision.py --lr_idx=1 --model=bert-vision --optimizer=adam\n",
            "2020-09-27 18:32:49.331225: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdar-tau\u001b[0m (use `wandb login --relogin` to force relogin)\n",
            "2020-09-27 18:32:52,842 - wandb.wandb_agent - INFO - Running runs: ['t8s7v74o']\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20200927_183252-t8s7v74o\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mglorious-sweep-7\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/dar-tau/bert-vision\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/dar-tau/bert-vision/sweeps/ti2qxgh0\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/dar-tau/bert-vision/runs/t8s7v74o\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
            "\n",
            "  0%|          | 0/6250 [00:00<?, ?it/s][W TensorIterator.cpp:918] Warning: Mixed memory format inputs detected while calling the operator. The operator will output contiguous tensor even if some of the inputs are in channels_last format. (function operator())\n",
            " 83%|████████▎ | 5173/6250 [49:49<10:18,  1.74it/s]2020-09-27 19:22:50,415 - wandb.wandb_agent - INFO - Agent received command: stop\n",
            "2020-09-27 19:22:50,415 - wandb.wandb_agent - INFO - Stop: t8s7v74o\n",
            "2020-09-27 19:22:55,423 - wandb.wandb_agent - INFO - Cleaning up finished run: t8s7v74o\n",
            "2020-09-27 19:22:55,672 - wandb.wandb_agent - INFO - Agent received command: run\n",
            "2020-09-27 19:22:55,672 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
            "\tlr_idx: 1\n",
            "\tmodel: bert-vision\n",
            "\toptimizer: sgd\n",
            "2020-09-27 19:22:55,673 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python bert-vision.py --lr_idx=1 --model=bert-vision --optimizer=sgd\n",
            "2020-09-27 19:22:57.195927: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "Files already downloaded and verified\n",
            "/usr/lib/python3.6/multiprocessing/semaphore_tracker.py:143: UserWarning: semaphore_tracker: There appear to be 6 leaked semaphores to clean up at shutdown\n",
            "  len(cache))\n",
            "Files already downloaded and verified\n",
            "2020-09-27 19:23:00,683 - wandb.wandb_agent - INFO - Running runs: ['5wwdwh2l']\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdar-tau\u001b[0m (use `wandb login --relogin` to force relogin)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20200927_192300-5wwdwh2l\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33melated-sweep-8\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/dar-tau/bert-vision\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/dar-tau/bert-vision/sweeps/ti2qxgh0\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/dar-tau/bert-vision/runs/5wwdwh2l\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 1078\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20200927_192300-5wwdwh2l/logs/debug.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20200927_192300-5wwdwh2l/logs/debug-internal.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33melated-sweep-8\u001b[0m: \u001b[34mhttps://wandb.ai/dar-tau/bert-vision/runs/5wwdwh2l\u001b[0m\n",
            "2020-09-27 19:23:05,764 - wandb.wandb_agent - INFO - Cleaning up finished run: 5wwdwh2l\n",
            "2020-09-27 19:23:06,106 - wandb.wandb_agent - INFO - Agent received command: run\n",
            "2020-09-27 19:23:06,106 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
            "\tlr_idx: 2\n",
            "\tmodel: resnet\n",
            "\toptimizer: adam\n",
            "2020-09-27 19:23:06,107 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python bert-vision.py --lr_idx=2 --model=resnet --optimizer=adam\n",
            "2020-09-27 19:23:07.572771: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdar-tau\u001b[0m (use `wandb login --relogin` to force relogin)\n",
            "2020-09-27 19:23:11,117 - wandb.wandb_agent - INFO - Running runs: ['ue8frc1e']\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20200927_192311-ue8frc1e\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msmart-sweep-9\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/dar-tau/bert-vision\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/dar-tau/bert-vision/sweeps/ti2qxgh0\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/dar-tau/bert-vision/runs/ue8frc1e\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
            "\n",
            " 80%|███████▉  | 4969/6250 [03:27<00:54, 23.30it/s]2020-09-27 19:26:44,838 - wandb.wandb_agent - INFO - Agent received command: stop\n",
            "2020-09-27 19:26:44,838 - wandb.wandb_agent - INFO - Stop: ue8frc1e\n",
            "2020-09-27 19:26:49,844 - wandb.wandb_agent - INFO - Cleaning up finished run: ue8frc1e\n",
            "2020-09-27 19:26:50,009 - wandb.wandb_agent - INFO - Agent received command: run\n",
            "2020-09-27 19:26:50,009 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
            "\tlr_idx: 2\n",
            "\tmodel: resnet\n",
            "\toptimizer: sgd\n",
            "2020-09-27 19:26:50,010 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python bert-vision.py --lr_idx=2 --model=resnet --optimizer=sgd\n",
            "2020-09-27 19:26:51.492610: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdar-tau\u001b[0m (use `wandb login --relogin` to force relogin)\n",
            "2020-09-27 19:26:55,020 - wandb.wandb_agent - INFO - Running runs: ['rrdafce2']\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20200927_192654-rrdafce2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mlunar-sweep-10\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/dar-tau/bert-vision\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/dar-tau/bert-vision/sweeps/ti2qxgh0\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/dar-tau/bert-vision/runs/rrdafce2\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
            "\n",
            "/usr/lib/python3.6/multiprocessing/semaphore_tracker.py:143: UserWarning: semaphore_tracker: There appear to be 6 leaked semaphores to clean up at shutdown\n",
            "  len(cache))\n",
            "100%|██████████| 6250/6250 [02:51<00:00, 36.41it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 1177\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20200927_192654-rrdafce2/logs/debug.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20200927_192654-rrdafce2/logs/debug-internal.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         loss 1.776249885559082\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          acc 0.20864\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        _step 6249\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     _runtime 178\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   _timestamp 1601234993\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         loss █▆▆▇▆▆▆▆▆▆▇▅▃▅▇█▄▅▄▄▃▄▃▄▃▆▂▅▃▅▅▃▁▇▃▁▄▂▃▄\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          acc ▁▁▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇█████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        _step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     _runtime ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   _timestamp ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mlunar-sweep-10\u001b[0m: \u001b[34mhttps://wandb.ai/dar-tau/bert-vision/runs/rrdafce2\u001b[0m\n",
            "2020-09-27 19:29:58,234 - wandb.wandb_agent - INFO - Cleaning up finished run: rrdafce2\n",
            "2020-09-27 19:29:58,466 - wandb.wandb_agent - INFO - Agent received command: run\n",
            "2020-09-27 19:29:58,466 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
            "\tlr_idx: 2\n",
            "\tmodel: bert-vision\n",
            "\toptimizer: adam\n",
            "2020-09-27 19:29:58,467 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python bert-vision.py --lr_idx=2 --model=bert-vision --optimizer=adam\n",
            "2020-09-27 19:29:59.954717: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdar-tau\u001b[0m (use `wandb login --relogin` to force relogin)\n",
            "2020-09-27 19:30:03,477 - wandb.wandb_agent - INFO - Running runs: ['x218iswr']\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20200927_193003-x218iswr\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mhearty-sweep-11\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/dar-tau/bert-vision\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/dar-tau/bert-vision/sweeps/ti2qxgh0\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/dar-tau/bert-vision/runs/x218iswr\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
            "\n",
            "  0%|          | 0/6250 [00:00<?, ?it/s][W TensorIterator.cpp:918] Warning: Mixed memory format inputs detected while calling the operator. The operator will output contiguous tensor even if some of the inputs are in channels_last format. (function operator())\n",
            " 31%|███       | 1934/6250 [18:36<41:47,  1.72it/s]2020-09-27 19:48:48,120 - wandb.wandb_agent - INFO - Agent received command: stop\n",
            "2020-09-27 19:48:48,120 - wandb.wandb_agent - INFO - Stop: x218iswr\n",
            "2020-09-27 19:48:53,123 - wandb.wandb_agent - INFO - Cleaning up finished run: x218iswr\n",
            "2020-09-27 19:48:53,299 - wandb.wandb_agent - INFO - Agent received command: run\n",
            "2020-09-27 19:48:53,299 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
            "\tlr_idx: 2\n",
            "\tmodel: bert-vision\n",
            "\toptimizer: sgd\n",
            "2020-09-27 19:48:53,300 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python bert-vision.py --lr_idx=2 --model=bert-vision --optimizer=sgd\n",
            "2020-09-27 19:48:54.832363: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "/usr/lib/python3.6/multiprocessing/semaphore_tracker.py:143: UserWarning: semaphore_tracker: There appear to be 6 leaked semaphores to clean up at shutdown\n",
            "  len(cache))\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "2020-09-27 19:48:58,309 - wandb.wandb_agent - INFO - Running runs: ['a9f6299e']\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdar-tau\u001b[0m (use `wandb login --relogin` to force relogin)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20200927_194858-a9f6299e\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mcurious-sweep-12\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/dar-tau/bert-vision\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/dar-tau/bert-vision/sweeps/ti2qxgh0\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/dar-tau/bert-vision/runs/a9f6299e\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 1297\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20200927_194858-a9f6299e/logs/debug.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20200927_194858-a9f6299e/logs/debug-internal.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mcurious-sweep-12\u001b[0m: \u001b[34mhttps://wandb.ai/dar-tau/bert-vision/runs/a9f6299e\u001b[0m\n",
            "2020-09-27 19:49:03,385 - wandb.wandb_agent - INFO - Cleaning up finished run: a9f6299e\n",
            "2020-09-27 19:49:03,562 - wandb.wandb_agent - INFO - Agent received command: run\n",
            "2020-09-27 19:49:03,562 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
            "\tlr_idx: 3\n",
            "\tmodel: resnet\n",
            "\toptimizer: adam\n",
            "2020-09-27 19:49:03,564 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python bert-vision.py --lr_idx=3 --model=resnet --optimizer=adam\n",
            "2020-09-27 19:49:05.101155: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "2020-09-27 19:49:08,574 - wandb.wandb_agent - INFO - Running runs: ['bftugn8c']\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdar-tau\u001b[0m (use `wandb login --relogin` to force relogin)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20200927_194908-bftugn8c\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfancy-sweep-13\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/dar-tau/bert-vision\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/dar-tau/bert-vision/sweeps/ti2qxgh0\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/dar-tau/bert-vision/runs/bftugn8c\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
            "\n",
            "100%|██████████| 6250/6250 [04:22<00:00, 23.82it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 1342\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20200927_194908-bftugn8c/logs/debug.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20200927_194908-bftugn8c/logs/debug-internal.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         loss 2.5801174640655518\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          acc 0.22758\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        _step 6249\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     _runtime 268\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   _timestamp 1601236417\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         loss █▇▇▇▄▅▄▆▆▅▄▅▅▄▄▃▅▄▃▃▃▂▄▃▄▅▆▃▂▃▃▃▃▇▄▅▄▅▁▃\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          acc ▁▁▂▂▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇██████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        _step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     _runtime ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   _timestamp ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mfancy-sweep-13\u001b[0m: \u001b[34mhttps://wandb.ai/dar-tau/bert-vision/runs/bftugn8c\u001b[0m\n",
            "2020-09-27 19:53:43,284 - wandb.wandb_agent - INFO - Cleaning up finished run: bftugn8c\n",
            "2020-09-27 19:53:43,530 - wandb.wandb_agent - INFO - Agent received command: run\n",
            "2020-09-27 19:53:43,530 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
            "\tlr_idx: 3\n",
            "\tmodel: resnet\n",
            "\toptimizer: sgd\n",
            "2020-09-27 19:53:43,531 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python bert-vision.py --lr_idx=3 --model=resnet --optimizer=sgd\n",
            "2020-09-27 19:53:45.040164: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdar-tau\u001b[0m (use `wandb login --relogin` to force relogin)\n",
            "2020-09-27 19:53:48,540 - wandb.wandb_agent - INFO - Running runs: ['izgbvoiu']\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20200927_195348-izgbvoiu\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mworthy-sweep-14\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/dar-tau/bert-vision\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/dar-tau/bert-vision/sweeps/ti2qxgh0\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/dar-tau/bert-vision/runs/izgbvoiu\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
            "\n",
            "100%|██████████| 6250/6250 [02:52<00:00, 36.27it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 1391\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20200927_195348-izgbvoiu/logs/debug.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20200927_195348-izgbvoiu/logs/debug-internal.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         loss 4.480893135070801\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          acc 0.02726\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        _step 6249\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     _runtime 178\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   _timestamp 1601236607\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         loss ▃█▄▃▅▃▆▃▅▆▅▆▃▅▅▃▂▅▃▁▄▃▄▄▄▃▃▄▃▅▂▅▄▄▄▁▄▄▂▂\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          acc ▁▃▃▃▃▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        _step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     _runtime ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   _timestamp ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mworthy-sweep-14\u001b[0m: \u001b[34mhttps://wandb.ai/dar-tau/bert-vision/runs/izgbvoiu\u001b[0m\n",
            "2020-09-27 19:56:51,674 - wandb.wandb_agent - INFO - Cleaning up finished run: izgbvoiu\n",
            "2020-09-27 19:56:51,840 - wandb.wandb_agent - INFO - Agent received command: run\n",
            "2020-09-27 19:56:51,841 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
            "\tlr_idx: 3\n",
            "\tmodel: bert-vision\n",
            "\toptimizer: adam\n",
            "2020-09-27 19:56:51,842 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python bert-vision.py --lr_idx=3 --model=bert-vision --optimizer=adam\n",
            "2020-09-27 19:56:53.283570: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdar-tau\u001b[0m (use `wandb login --relogin` to force relogin)\n",
            "2020-09-27 19:56:56,847 - wandb.wandb_agent - INFO - Running runs: ['lr18eceo']\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20200927_195656-lr18eceo\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mhelpful-sweep-15\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/dar-tau/bert-vision\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/dar-tau/bert-vision/sweeps/ti2qxgh0\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/dar-tau/bert-vision/runs/lr18eceo\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
            "\n",
            "  0%|          | 0/6250 [00:00<?, ?it/s][W TensorIterator.cpp:918] Warning: Mixed memory format inputs detected while calling the operator. The operator will output contiguous tensor even if some of the inputs are in channels_last format. (function operator())\n",
            " 16%|█▌        | 972/6250 [09:21<50:33,  1.74it/s]2020-09-27 20:06:26,803 - wandb.wandb_agent - INFO - Agent received command: stop\n",
            "2020-09-27 20:06:26,803 - wandb.wandb_agent - INFO - Stop: lr18eceo\n",
            "2020-09-27 20:06:31,809 - wandb.wandb_agent - INFO - Cleaning up finished run: lr18eceo\n",
            "2020-09-27 20:06:32,002 - wandb.wandb_agent - INFO - Agent received command: run\n",
            "2020-09-27 20:06:32,002 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
            "\tlr_idx: 3\n",
            "\tmodel: bert-vision\n",
            "\toptimizer: sgd\n",
            "2020-09-27 20:06:32,003 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python bert-vision.py --lr_idx=3 --model=bert-vision --optimizer=sgd\n",
            "2020-09-27 20:06:33.444745: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdar-tau\u001b[0m (use `wandb login --relogin` to force relogin)\n",
            "2020-09-27 20:06:37,015 - wandb.wandb_agent - INFO - Running runs: ['vhx4cr21']\n",
            "/usr/lib/python3.6/multiprocessing/semaphore_tracker.py:143: UserWarning: semaphore_tracker: There appear to be 6 leaked semaphores to clean up at shutdown\n",
            "  len(cache))\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20200927_200636-vhx4cr21\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mgallant-sweep-16\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/dar-tau/bert-vision\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/dar-tau/bert-vision/sweeps/ti2qxgh0\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/dar-tau/bert-vision/runs/vhx4cr21\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 1501\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20200927_200636-vhx4cr21/logs/debug.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20200927_200636-vhx4cr21/logs/debug-internal.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mgallant-sweep-16\u001b[0m: \u001b[34mhttps://wandb.ai/dar-tau/bert-vision/runs/vhx4cr21\u001b[0m\n",
            "2020-09-27 20:06:42,092 - wandb.wandb_agent - INFO - Cleaning up finished run: vhx4cr21\n",
            "2020-09-27 20:06:42,256 - wandb.wandb_agent - INFO - Agent received command: exit\n",
            "2020-09-27 20:06:42,256 - wandb.wandb_agent - INFO - Received exit command. Killing runs and quitting.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Terminating and syncing runs. Press ctrl-c to kill.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMj5CiiIlzJc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oT_5ShNJmBcx"
      },
      "source": [
        "# Experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sS-kATGqeQfc"
      },
      "source": [
        "\n",
        "class DummyLayer(nn.Module):\n",
        "  def __init__(self, *args, **kwargs):\n",
        "    super().__init__()\n",
        "    pass\n",
        "  def forward(self, x, *args, **kwargs):\n",
        "    return x\n",
        "\n",
        "class PlainBERT(nn.Module):\n",
        "    def __init__(self, n_tokens, min_layer = None):\n",
        "        super().__init__()\n",
        "        self.nLayers = 6\n",
        "        self.nHeads = 12\n",
        "        self.seqLen = 512\n",
        "\n",
        "\n",
        "        bert = AutoModel.from_pretrained('distilbert-base-uncased', cache_dir = cache_dir)\n",
        "        self.position_embeddings = nn.Parameter(torch.Tensor(bert.embeddings.position_embeddings(torch.arange(self.seqLen)).detach().numpy()))\n",
        "        if min_layer is None:\n",
        "          self.bert = bert.transformer\n",
        "        else:\n",
        "          raise NotImplementedError\n",
        "          bert_ = bert.transformer\n",
        "          for n, m in bert_.layer.named_children():\n",
        "            if int(n) < min_layer:\n",
        "              setattr(bert_.layer, n, DummyLayer())\n",
        "        \n",
        "          self.bert = bert_\n",
        "\n",
        "        self.bert.requires_grad_(False)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.bert.forward(x + self.position_embeddings, attn_mask = torch.ones(x.size(0), 512).to(x.device),\n",
        "                                head_mask = torch.ones(self.nLayers, x.size(0), self.nHeads, self.seqLen, self.seqLen).to(x.device))\n",
        "\n",
        "class BertVision(nn.Module):\n",
        "    def __init__(self,  n_classes, img_dim):\n",
        "        super().__init__()\n",
        "        self.with_classifier = True\n",
        "        self.n_tokens = np.prod(img_dim)\n",
        "        self.top = nn.Sequential(\n",
        "                                 nn.Conv2d(3, 32, 3, padding = 1 ),\n",
        "                                 nn.LeakyReLU(0.2),\n",
        "                                 nn.Conv2d(32, 100, 3, padding = 1),\n",
        "                                 nn.LeakyReLU(0.2),\n",
        "                                 nn.Conv2d(100, 200, 3, padding = 1),\n",
        "                                 nn.LeakyReLU(0.2),\n",
        "                                 nn.Conv2d(200, 768, 3, stride = (1, 2), padding = 1),\n",
        "                                 nn.LeakyReLU(0.2)\n",
        "                                )\n",
        "        \n",
        "        self.top.apply(self._init_top)\n",
        "        self.bert = PlainBERT(n_tokens = self.n_tokens)\n",
        "        self.fc = nn.Linear(768 * self.n_tokens//2, n_classes)\n",
        "        self.layer_norm = nn.LayerNorm((512,))\n",
        "\n",
        "    def toggleIntermediate(self):\n",
        "        self.with_classifier = !self.with_classifier\n",
        "    \n",
        "    \n",
        "    def _init_top(self, m):\n",
        "        if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
        "            nn.init.kaiming_uniform_(m.weight)\n",
        "            m.bias.data.fill_(0.01)\n",
        "        pass\n",
        "    def forward(self, x):\n",
        "        x = self.top(x)\n",
        "        x = x.view(x.size(0), x.size(1), -1)\n",
        "        x = x.transpose(1,2)\n",
        "        x = self.bert(x)\n",
        "        x = torch.stack(x).squeeze(0)\n",
        "        x = x.transpose(1,2).contiguous()\n",
        "#         x = self.layer_norm(x)\n",
        "#         x = torch.mean(x, dim = (-2,))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        if self.with_classifier:\n",
        "            x = self.fc(x)\n",
        "        return x.squeeze(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Udifw4deQfn",
        "outputId": "e7c6ea1a-d948-41e3-f421-b3d6822a3483"
      },
      "source": [
        "device = 'cuda'\n",
        "train_ds = CIFAR100(\"{}/data/cifar100\".format(guy_folder), download = True, transform=transforms.ToTensor())\n",
        "test_ds = CIFAR100(\"{}/data/cifar100\".format(guy_folder), download = True, transform=transforms.ToTensor(), train = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to /notebooks//data/cifar100/cifar-100-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "169009152it [00:09, 18300545.88it/s]                               \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /notebooks//data/cifar100/cifar-100-python.tar.gz to /notebooks//data/cifar100\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ixPIuePqq86"
      },
      "source": [
        "%%script false\n",
        "# After login in through firefox to ImageNet\n",
        "%cd {guy_folder}/data\n",
        "!wget http://www.image-net.org/archive/stanford/fall11_whole.tar\n",
        "# !tar -xvf "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnJGD7m7qfSw"
      },
      "source": [
        "%%script false\n",
        "train_folder = \"{}/data/imagenet12/train\".format(guy_folder)\n",
        "\n",
        "train_ds = ImageFolder(train_folder,\n",
        "            transform = transforms.Compose([transforms.ToTensor()]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3MFYU_SeQfx"
      },
      "source": [
        "from collections import defaultdict\n",
        "batch_size = 8\n",
        "total = int(len(train_ds)/batch_size )\n",
        "\n",
        "from tqdm import tqdm_notebook, tqdm\n",
        "class_rep = defaultdict(int)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr = 1e-6)\n",
        "train_dataloader = DataLoader(train_ds, batch_size = batch_size, shuffle = True)\n",
        "test_dataloader = DataLoader(test_ds, batch_size = batch_size, shuffle = True)\n",
        "pbar = tqdm(enumerate(train_dataloader), total = total, leave = True, position = 0)\n",
        "acc_sum = 0\n",
        "\n",
        "for i, (x,y) in pbar:\n",
        "    if i >= total:\n",
        "        break\n",
        "    model.eval()\n",
        "    x_test, y_test = next(iter(test_dataloader))\n",
        "    test_acc = ((model(x_test.to(device)).argmax(dim =  -1) == y_test.to(device)).sum()).item()/batch_size\n",
        "    model.train()\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    y = y.to(device)\n",
        "    yhat = model(x.to(device))\n",
        "    loss = criterion(yhat, y)\n",
        "    acc_sum += (yhat.argmax(dim =  -1) == y).sum()\n",
        "    class_rep[y[0].item()] += 1 # Incomplete\n",
        "    topk = np.where(np.argsort(yhat[0].cpu().detach().numpy()) == y[0].detach().cpu().numpy())[0][0] # TODO: Incomplete\n",
        "    \n",
        "    pbar.set_postfix_str(\"Loss: {:.2f} Test Acc: {:.2f} Acc: {:.2f} Top: {} Class: {}\".format(loss.item(),\n",
        "                                                                                               test_acc, \n",
        "                                                                             acc_sum.item()/float(batch_size * (i+1)), \n",
        "                                                                             topk, class_rep[y[0].item()]))\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ul5_1EQo4ynl",
        "outputId": "6d8957e3-3276-4c16-9cd4-e8bc8a7c58f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "from collections import defaultdict\n",
        "batch_size = 32\n",
        "total = int(len(train_ds)/batch_size )\n",
        "\n",
        "from tqdm import tqdm_notebook, tqdm\n",
        "class_rep = defaultdict(int)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(vision_model.parameters(), lr = 1e-2)\n",
        "train_dataloader = DataLoader(train_ds, batch_size = batch_size, shuffle = True)\n",
        "pbar = tqdm(enumerate(train_dataloader), total = total, leave = True, position = 0)\n",
        "acc_sum = 0\n",
        "\n",
        "for i, (x,y) in pbar:\n",
        "    if i >= total:\n",
        "        break\n",
        "    optimizer.zero_grad()\n",
        "    y = y.to(device)\n",
        "    # x = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "    #         std=[0.229, 0.224, 0.225],)(x)\n",
        "    yhat = vision_model(x.to(device))\n",
        "    loss = criterion(yhat, y)\n",
        "    acc_sum += (yhat.argmax(dim =  -1) == y).sum()\n",
        "    class_rep[y[0].item()] += 1 # Incomplete\n",
        "    topk = np.where(np.argsort(yhat[0].cpu().detach().numpy()) == y[0].detach().cpu().numpy())[0][0] # TODO: Incomplete\n",
        "    pbar.set_postfix_str(\"Loss: {:.2f} Acc: {:.2f} Top: {} Class: {}\".format(loss.item(), \n",
        "                                                                            acc_sum.item()/float(batch_size * (i+1)), \n",
        "                                                                            topk, class_rep[y[0].item()]))\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 1561/1562 [02:02<00:00, 12.76it/s, Loss: 3.81 Acc: 0.07 Top: 93 Class: 12]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iOzYWVLeQf1"
      },
      "source": [
        "y  = []\n",
        "z = []\n",
        "for x, _  in tqdm(train_ds):\n",
        "    z.append(x)\n",
        "    y.append((model(x.to(device).unsqueeze(0))).detach())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-3XJcm1eQf5"
      },
      "source": [
        "y = torch.stack(y)\n",
        "z = torch.stack(z)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FqeYGjteQf9",
        "outputId": "825df2ce-a86d-427c-cbf8-afe92780eddb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "z.std()/y.std()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1882, device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQ5EySnveQgC"
      },
      "source": [
        "i = np.random.choice(len(train_ds))\n",
        "print(F.softmax(model(train_ds[i][0].unsqueeze(0).to(device))))\n",
        "print(model(train_ds[i][0].unsqueeze(0).to(device)).argmax())\n",
        "print(train_ds[i][1])\n",
        "t = transforms.Compose([\n",
        "#     transforms.Grayscale(),\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Grayscale(3),\n",
        "    transforms.ToTensor(),\n",
        "    \n",
        "    ])(train_ds[i][0])\n",
        "print(F.softmax(model(t.unsqueeze(0).to(device))))\n",
        "print(model(t.unsqueeze(0).to(device)).argmax())\n",
        "\n",
        "print(F.softmax(model(((train_ds[i+1][0])).unsqueeze(0).to(device))))\n",
        "print(F.softmax(model(((train_ds[i+1][0])).unsqueeze(0).to(device))).argmax())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncJnwGykeQgH"
      },
      "source": [
        "model.load_state_dict(state_dict,strict = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPjRCbmAeQgL"
      },
      "source": [
        "model.toggleIntermediate()\n",
        "i = np.random.choice(len(train_ds))\n",
        "a1 = (F.softmax(model(train_ds[i][0].unsqueeze(0).to(device))))\n",
        "\n",
        "t = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Grayscale(3),\n",
        "#     transforms.ColorJitter(10,10, 10),\n",
        "#     transforms.RandomRotation(90),\n",
        "    transforms.ToTensor(),\n",
        "    \n",
        "    ])(train_ds[i][0])\n",
        "a2 = (F.softmax(model(t.unsqueeze(0).to(device))))\n",
        "\n",
        "a3 = (F.softmax(model(((train_ds[i+1][0])).to(device).unsqueeze(0))))\n",
        "\n",
        "\n",
        "print(torch.norm(a1-a2, p = 2))\n",
        "print(torch.norm(a1-a3, p = 2))\n",
        "print(torch.norm(a2-a3, p = 2))\n",
        "model.toggleIntermediate()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}