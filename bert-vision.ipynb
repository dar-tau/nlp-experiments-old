{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "bert-vision.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfj6qUCzeQfA"
      },
      "source": [
        "## Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMUnskJ9eQfB"
      },
      "source": [
        "storageName = 'university'\n",
        "\n",
        "if storageName == 'paperspace': \n",
        "    guy_folder = \"/notebooks/\"\n",
        "elif storageName == 'colab':\n",
        "    guy_folder = \"/content/\"\n",
        "elif storageName == 'university':\n",
        "    guy_folder = '/vol/scratch/guy/'\n",
        "    \n",
        "    \n",
        "cache_dir = guy_folder+\"/cache/transformer_cache\""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3z5yhLLlzFk"
      },
      "source": [
        "%pip uninstall -y enum34"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqAi8nT2eQfG",
        "outputId": "d037e9cb-428a-49d6-db5e-624ebda582d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# %pip install matplotlib seaborn pandas tqdm tensorboard\n",
        "\n",
        "%cd {guy_folder}\n",
        "!mkdir cache\n",
        "!mkdir cache/transformer_cache\n",
        "# %pip install --no-cache-dir --upgrade torch torchvision\n",
        "#==1.4.0+cu100 torchvision== -f https://download.pytorch.org/whl/torch_stable.html\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htC1bYBQfkz6",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "source": [
        "%pip install wandb\n",
        "%cd {guy_folder}/cache/\n",
        "!git clone https://github.com/huggingface/transformers.git\n",
        "%pip install ./transformers\n",
        "%pip install -U nlp\n",
        "\n",
        "%cd {guy_folder}\n",
        "\n",
        "## Not working!!!\n",
        "!setenv TRANSFORMERS_CACHE /vol/scratch/guy/cache/transformer_cache\n",
        "!setenv CUDA_VISIBLE_DEVICES 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KPmqdmNj6dN"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhRzzS1eeQfZ"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets import ImageNet, ImageFolder, CIFAR10, CIFAR100\n",
        "from torchvision import transforms\n",
        "from torchvision.models import resnet101\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from transformers import AdamW\n",
        "import wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wks3jN_niRZ7"
      },
      "source": [
        "# Sweep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5RPTY5Ww0Fq"
      },
      "source": [
        "from getpass import getpass\n",
        "!wandb login {getpass()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mo6pVi-alzI9",
        "outputId": "787f36eb-08f2-49da-9722-8d605d2ea437",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "%%writefile bert-vision.py\n",
        "\n",
        "storageName = 'colab'\n",
        "\n",
        "if storageName == 'paperspace': \n",
        "    guy_folder = \"/notebooks/\"\n",
        "elif storageName == 'colab':\n",
        "    guy_folder = \"/content/\"\n",
        "elif storageName == 'university':\n",
        "    guy_folder = '/vol/scratch/guy/'\n",
        "\n",
        "    \n",
        "cache_dir = guy_folder + \"/cache/transformer_cache\"\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets import ImageNet, ImageFolder, CIFAR10, CIFAR100\n",
        "from torchvision import transforms\n",
        "from torchvision.models import resnet101, resnet50\n",
        "from transformers import AutoModel, AutoTokenizer, AutoConfig\n",
        "from transformers import AdamW\n",
        "import wandb\n",
        "import os.path\n",
        "\n",
        "assert(os.path.isdir(cache_dir))\n",
        "\n",
        "\n",
        "class DummyLayer(nn.Module):\n",
        "  def __init__(self, *args, **kwargs):\n",
        "    super().__init__()\n",
        "    pass\n",
        "  def forward(self, x, *args, **kwargs):\n",
        "    return x\n",
        "\n",
        "class PlainBERT(nn.Module):\n",
        "    def __init__(self, n_tokens, min_layer = None, pretrained = True):\n",
        "        super().__init__()\n",
        "        self.nLayers = 6\n",
        "        self.nHeads = 12\n",
        "        self.seqLen = 512\n",
        "\n",
        "        modelName = 'distilbert-base-uncased'\n",
        "        if pretrained:\n",
        "          bert = AutoModel.from_pretrained(modelName, cache_dir = cache_dir)\n",
        "        else:\n",
        "          bertConfig = AutoConfig.from_pretrained(modelName, cache_dir = cache_dir)\n",
        "          bert = AutoModel.from_config(bertConfig)\n",
        "\n",
        "        self.position_embeddings = nn.Parameter(\n",
        "            torch.Tensor(bert.embeddings.position_embeddings(torch.arange(self.seqLen)).detach().numpy()))\n",
        "        if min_layer is None:\n",
        "          self.bert = bert.transformer\n",
        "        else:\n",
        "          raise NotImplementedError\n",
        "          bert_ = bert.transformer\n",
        "          for n, m in bert_.layer.named_children():\n",
        "            if int(n) < min_layer:\n",
        "              setattr(bert_.layer, n, DummyLayer())\n",
        "        \n",
        "          self.bert = bert_\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.bert.forward(x + self.position_embeddings, attn_mask = torch.ones(x.size(0), 512).to(x.device),\n",
        "                                head_mask = torch.ones(self.nLayers, x.size(0), \n",
        "                                                       self.nHeads, self.seqLen, self.seqLen).to(x.device))\n",
        "\n",
        "class BertVision(nn.Module):\n",
        "    def __init__(self,  n_classes, img_dim, pretrained = True,\n",
        "                 freeze = False):\n",
        "        super().__init__()\n",
        "        self.with_classifier = True\n",
        "        self.n_tokens = np.prod(img_dim)\n",
        "        self.top = nn.Sequential(\n",
        "                                 nn.Conv2d(3, 32, 3, padding = 1 ),\n",
        "                                 nn.LeakyReLU(0.2),\n",
        "                                 nn.Conv2d(32, 100, 3, padding = 1),\n",
        "                                 nn.LeakyReLU(0.2),\n",
        "                                 nn.Conv2d(100, 200, 3, padding = 1),\n",
        "                                 nn.LeakyReLU(0.2),\n",
        "                                 nn.Conv2d(200, 768, 3, stride = (1, 2), padding = 1),\n",
        "                                 nn.LeakyReLU(0.2)\n",
        "                                )\n",
        "        \n",
        "        self.top.apply(self._init_top)\n",
        "        self.bert = PlainBERT(n_tokens = self.n_tokens, pretrained = pretrained)\n",
        "        self.fc = nn.Linear(768 * self.n_tokens//2, n_classes)\n",
        "        self.layer_norm = nn.LayerNorm((512,))\n",
        "        if freeze: \n",
        "          self.bert.requires_grad_(False)\n",
        "\n",
        "    def toggleIntermediate(self):\n",
        "        self.with_classifier = not self.with_classifier\n",
        "    \n",
        "    \n",
        "    def _init_top(self, m):\n",
        "        if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
        "            nn.init.kaiming_uniform_(m.weight)\n",
        "            m.bias.data.fill_(0.01)\n",
        "        pass\n",
        "    def forward(self, x):\n",
        "        x = self.top(x)\n",
        "        x = x.view(x.size(0), x.size(1), -1)\n",
        "        x = x.transpose(1,2)\n",
        "        x = self.bert(x)\n",
        "        x = torch.stack(x).squeeze(0)\n",
        "        x = x.transpose(1,2).contiguous()\n",
        "#         x = self.layer_norm(x)\n",
        "#         x = torch.mean(x, dim = (-2,))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        if self.with_classifier:\n",
        "            x = self.fc(x)\n",
        "        return x.squeeze(1)\n",
        "    \n",
        "    \n",
        "    \n",
        "device = 'cuda'\n",
        "train_ds = CIFAR100(\"{}/data/cifar100\".format(guy_folder), download = True, transform=transforms.ToTensor())\n",
        "test_ds = CIFAR100(\"{}/data/cifar100\".format(guy_folder), download = True, transform=transforms.ToTensor(), train = False)\n",
        "\n",
        "\n",
        "batch_size = 8\n",
        "\n",
        "lr = {'bert-vision': [1e-6, 5e-6, 1e-5, 5e-5],\n",
        "      'resnet': [3e-4, 1e-3, 3e-3, 1e-2]\n",
        "      }\n",
        "\n",
        "optimizerDict = {'adam': torch.optim.Adam,\n",
        "                 'adamw': AdamW,\n",
        "                 'sgd': torch.optim.SGD, # No momentum\n",
        "                 }\n",
        "\n",
        "def makeModel(modelName, pretrained, freeze):\n",
        "  if modelName == 'resnet':\n",
        "    model_resnet = resnet50(pretrained = pretrained)\n",
        "    if freeze:\n",
        "      model_resnet.requires_grad_(False)\n",
        "    model_resnet.fc = nn.Linear(model_resnet.fc.in_features, 100)\n",
        "    model_resnet.to(device)\n",
        "    model = model_resnet\n",
        "  elif modelName == 'bert-vision':\n",
        "    model = BertVision(len(train_ds.classes), (32,32), pretrained = pretrained,\n",
        "                       freeze = freeze).to(device)\n",
        "  else:\n",
        "    model = Sequential()\n",
        "  return model\n",
        "\n",
        "def _convertBool(s):\n",
        "  s = s.lower()\n",
        "  assert(s in ['true', 'false'])\n",
        "  return s == 'true'\n",
        "\n",
        "\n",
        "def train(config):\n",
        "  \n",
        "  optimizerAlg = optimizerDict[config.optimizer]\n",
        "  if config.model == 'bert-vision': \n",
        "    if config.optimizer == 'adam':\n",
        "      optimizerAlg = optimizerDict['adamw']\n",
        "    if config.optimizer == 'sgd':\n",
        "      return\n",
        "    \n",
        "\n",
        "  modelName = config.model\n",
        "  lr_idx = config.lr_idx\n",
        "  pretrained = _convertBool(config.pretrained)\n",
        "  freeze = _convertBool(config.freeze)\n",
        "  model = makeModel(modelName, pretrained = pretrained, freeze = freeze)\n",
        "\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = optimizerAlg(model.parameters(), lr = lr[modelName][lr_idx])\n",
        "  train_dataloader = DataLoader(train_ds, batch_size = batch_size, shuffle = True)\n",
        "  test_dataloader = DataLoader(test_ds, batch_size = batch_size, shuffle = True)\n",
        "  pbar = tqdm(train_dataloader, leave = True, position = 0)\n",
        "  acc_sum = 0\n",
        "\n",
        "  for i, (x,y) in enumerate(pbar):\n",
        "      model.train()    \n",
        "      optimizer.zero_grad()\n",
        "      y = y.to(device)\n",
        "      yhat = model(x.to(device))\n",
        "      loss = criterion(yhat, y)\n",
        "      acc_sum += (yhat.argmax(dim =  -1) == y).sum()    \n",
        "      wandb.log({'loss': loss.item(), \n",
        "                 'acc': acc_sum.item() / (batch_size * (i+1))})\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "wandb.init(project = 'bert-vision')\n",
        "\n",
        "from argparse import ArgumentParser\n",
        "parser = ArgumentParser()\n",
        "parser.add_argument('--lr_idx', type=int, default=0, metavar='N')\n",
        "parser.add_argument('--optimizer', type=str, default='adam', metavar='N')\n",
        "parser.add_argument('--pretrained', type=str, default='true', metavar='N')\n",
        "parser.add_argument('--model', type=str, default='bert-vision', metavar='N')\n",
        "parser.add_argument('--freeze', type=str, default='false', metavar='N')\n",
        "\n",
        "args = parser.parse_args()\n",
        "wandb.config.update(args)\n",
        "\n",
        "config = wandb.config\n",
        "train(config)\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting bert-vision.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJA22phbj1S6"
      },
      "source": [
        "config = {\n",
        "    'method': 'grid',\n",
        "    'program': 'bert-vision.py',\n",
        "    'parameters': \n",
        "    {\n",
        "        'lr_idx': {'values': [0, 1, 2, 3]},\n",
        "        'optimizer':{'values': ['adam', 'sgd']},\n",
        "        'model': {'values': ['resnet', 'bert-vision']},\n",
        "        'pretrained': [True, False]\n",
        "    }\n",
        "}\n",
        "sweep_id = wandb.sweep(config, project = 'bert-vision')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwZwLpMFyeNE"
      },
      "source": [
        "!python bert-vision.py --lr_idx=1 --model=bert-vision --optimizer=adam --pretrained=false --freeze=true"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fU3OwHktlzJR"
      },
      "source": [
        "assert(sweep_id.isalnum())\n",
        "!wandb agent {sweep_id}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMj5CiiIlzJc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oT_5ShNJmBcx"
      },
      "source": [
        "# Experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sS-kATGqeQfc"
      },
      "source": [
        "\n",
        "class DummyLayer(nn.Module):\n",
        "  def __init__(self, *args, **kwargs):\n",
        "    super().__init__()\n",
        "    pass\n",
        "  def forward(self, x, *args, **kwargs):\n",
        "    return x\n",
        "\n",
        "class PlainBERT(nn.Module):\n",
        "    def __init__(self, n_tokens, min_layer = None):\n",
        "        super().__init__()\n",
        "        self.nLayers = 6\n",
        "        self.nHeads = 12\n",
        "        self.seqLen = 512\n",
        "\n",
        "\n",
        "        bert = AutoModel.from_pretrained('distilbert-base-uncased', cache_dir = cache_dir)\n",
        "        self.position_embeddings = nn.Parameter(torch.Tensor(bert.embeddings.position_embeddings(torch.arange(self.seqLen)).detach().numpy()))\n",
        "        if min_layer is None:\n",
        "          self.bert = bert.transformer\n",
        "        else:\n",
        "          raise NotImplementedError\n",
        "          bert_ = bert.transformer\n",
        "          for n, m in bert_.layer.named_children():\n",
        "            if int(n) < min_layer:\n",
        "              setattr(bert_.layer, n, DummyLayer())\n",
        "        \n",
        "          self.bert = bert_\n",
        "        self.bert.requires_grad_(False)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.bert.forward(x + self.position_embeddings, attn_mask = torch.ones(x.size(0), 512).to(x.device),\n",
        "                                head_mask = torch.ones(self.nLayers, x.size(0), self.nHeads, self.seqLen, self.seqLen).to(x.device))\n",
        "\n",
        "class BertVision(nn.Module):\n",
        "    def __init__(self,  n_classes, img_dim):\n",
        "        super().__init__()\n",
        "        self.with_classifier = True\n",
        "        self.n_tokens = np.prod(img_dim)\n",
        "        self.top = nn.Sequential(\n",
        "                                 nn.Conv2d(3, 32, 3, padding = 1 ),\n",
        "                                 nn.LeakyReLU(0.2),\n",
        "                                 nn.Conv2d(32, 100, 3, padding = 1),\n",
        "                                 nn.LeakyReLU(0.2),\n",
        "                                 nn.Conv2d(100, 200, 3, padding = 1),\n",
        "                                 nn.LeakyReLU(0.2),\n",
        "                                 nn.Conv2d(200, 768, 3, stride = (1, 2), padding = 1),\n",
        "                                 nn.LeakyReLU(0.2)\n",
        "                                )\n",
        "        \n",
        "        self.top.apply(self._init_top)\n",
        "        self.bert = PlainBERT(n_tokens = self.n_tokens)\n",
        "        self.fc = nn.Linear(768 * self.n_tokens//2, n_classes)\n",
        "        self.layer_norm = nn.LayerNorm((512,))\n",
        "\n",
        "    def toggleIntermediate(self):\n",
        "        self.with_classifier = !self.with_classifier\n",
        "    \n",
        "    \n",
        "    def _init_top(self, m):\n",
        "        if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
        "            nn.init.kaiming_uniform_(m.weight)\n",
        "            m.bias.data.fill_(0.01)\n",
        "        pass\n",
        "    def forward(self, x):\n",
        "        x = self.top(x)\n",
        "        x = x.view(x.size(0), x.size(1), -1)\n",
        "        x = x.transpose(1,2)\n",
        "        x = self.bert(x)\n",
        "        x = torch.stack(x).squeeze(0)\n",
        "        x = x.transpose(1,2).contiguous()\n",
        "#         x = self.layer_norm(x)\n",
        "#         x = torch.mean(x, dim = (-2,))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        if self.with_classifier:\n",
        "            x = self.fc(x)\n",
        "        return x.squeeze(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Udifw4deQfn"
      },
      "source": [
        "device = 'cuda'\n",
        "train_ds = CIFAR100(\"{}/data/cifar100\".format(guy_folder), download = True, transform=transforms.ToTensor())\n",
        "test_ds = CIFAR100(\"{}/data/cifar100\".format(guy_folder), download = True, transform=transforms.ToTensor(), train = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ixPIuePqq86"
      },
      "source": [
        "%%script false\n",
        "# After login in through firefox to ImageNet\n",
        "%cd {guy_folder}/data\n",
        "!wget http://www.image-net.org/archive/stanford/fall11_whole.tar\n",
        "# !tar -xvf "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnJGD7m7qfSw"
      },
      "source": [
        "%%script false\n",
        "train_folder = \"{}/data/imagenet12/train\".format(guy_folder)\n",
        "\n",
        "train_ds = ImageFolder(train_folder,\n",
        "            transform = transforms.Compose([transforms.ToTensor()]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3MFYU_SeQfx"
      },
      "source": [
        "from collections import defaultdict\n",
        "batch_size = 8\n",
        "total = int(len(train_ds)/batch_size )\n",
        "\n",
        "from tqdm import tqdm_notebook, tqdm\n",
        "class_rep = defaultdict(int)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr = 1e-6)\n",
        "train_dataloader = DataLoader(train_ds, batch_size = batch_size, shuffle = True)\n",
        "test_dataloader = DataLoader(test_ds, batch_size = batch_size, shuffle = True)\n",
        "pbar = tqdm(enumerate(train_dataloader), total = total, leave = True, position = 0)\n",
        "acc_sum = 0\n",
        "\n",
        "for i, (x,y) in pbar:\n",
        "    if i >= total:\n",
        "        break\n",
        "    model.eval()\n",
        "    x_test, y_test = next(iter(test_dataloader))\n",
        "    test_acc = ((model(x_test.to(device)).argmax(dim =  -1) == y_test.to(device)).sum()).item()/batch_size\n",
        "    model.train()\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    y = y.to(device)\n",
        "    yhat = model(x.to(device))\n",
        "    loss = criterion(yhat, y)\n",
        "    acc_sum += (yhat.argmax(dim =  -1) == y).sum()\n",
        "    class_rep[y[0].item()] += 1 # Incomplete\n",
        "    topk = np.where(np.argsort(yhat[0].cpu().detach().numpy()) == y[0].detach().cpu().numpy())[0][0] # TODO: Incomplete\n",
        "    \n",
        "    pbar.set_postfix_str(\"Loss: {:.2f} Test Acc: {:.2f} Acc: {:.2f} Top: {} Class: {}\".format(loss.item(),\n",
        "                                                                                               test_acc, \n",
        "                                                                             acc_sum.item()/float(batch_size * (i+1)), \n",
        "                                                                             topk, class_rep[y[0].item()]))\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ul5_1EQo4ynl",
        "outputId": "6d8957e3-3276-4c16-9cd4-e8bc8a7c58f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "from collections import defaultdict\n",
        "batch_size = 32\n",
        "total = int(len(train_ds)/batch_size )\n",
        "\n",
        "from tqdm import tqdm_notebook, tqdm\n",
        "class_rep = defaultdict(int)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(vision_model.parameters(), lr = 1e-2)\n",
        "train_dataloader = DataLoader(train_ds, batch_size = batch_size, shuffle = True)\n",
        "pbar = tqdm(enumerate(train_dataloader), total = total, leave = True, position = 0)\n",
        "acc_sum = 0\n",
        "\n",
        "for i, (x,y) in pbar:\n",
        "    if i >= total:\n",
        "        break\n",
        "    optimizer.zero_grad()\n",
        "    y = y.to(device)\n",
        "    # x = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "    #         std=[0.229, 0.224, 0.225],)(x)\n",
        "    yhat = vision_model(x.to(device))\n",
        "    loss = criterion(yhat, y)\n",
        "    acc_sum += (yhat.argmax(dim =  -1) == y).sum()\n",
        "    class_rep[y[0].item()] += 1 # Incomplete\n",
        "    topk = np.where(np.argsort(yhat[0].cpu().detach().numpy()) == y[0].detach().cpu().numpy())[0][0] # TODO: Incomplete\n",
        "    pbar.set_postfix_str(\"Loss: {:.2f} Acc: {:.2f} Top: {} Class: {}\".format(loss.item(), \n",
        "                                                                            acc_sum.item()/float(batch_size * (i+1)), \n",
        "                                                                            topk, class_rep[y[0].item()]))\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 1561/1562 [02:02<00:00, 12.76it/s, Loss: 3.81 Acc: 0.07 Top: 93 Class: 12]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iOzYWVLeQf1"
      },
      "source": [
        "y  = []\n",
        "z = []\n",
        "for x, _  in tqdm(train_ds):\n",
        "    z.append(x)\n",
        "    y.append((model(x.to(device).unsqueeze(0))).detach())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-3XJcm1eQf5"
      },
      "source": [
        "y = torch.stack(y)\n",
        "z = torch.stack(z)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FqeYGjteQf9",
        "outputId": "825df2ce-a86d-427c-cbf8-afe92780eddb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "z.std()/y.std()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1882, device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQ5EySnveQgC"
      },
      "source": [
        "i = np.random.choice(len(train_ds))\n",
        "print(F.softmax(model(train_ds[i][0].unsqueeze(0).to(device))))\n",
        "print(model(train_ds[i][0].unsqueeze(0).to(device)).argmax())\n",
        "print(train_ds[i][1])\n",
        "t = transforms.Compose([\n",
        "#     transforms.Grayscale(),\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Grayscale(3),\n",
        "    transforms.ToTensor(),\n",
        "    \n",
        "    ])(train_ds[i][0])\n",
        "print(F.softmax(model(t.unsqueeze(0).to(device))))\n",
        "print(model(t.unsqueeze(0).to(device)).argmax())\n",
        "\n",
        "print(F.softmax(model(((train_ds[i+1][0])).unsqueeze(0).to(device))))\n",
        "print(F.softmax(model(((train_ds[i+1][0])).unsqueeze(0).to(device))).argmax())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncJnwGykeQgH"
      },
      "source": [
        "model.load_state_dict(state_dict,strict = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPjRCbmAeQgL"
      },
      "source": [
        "model.toggleIntermediate()\n",
        "i = np.random.choice(len(train_ds))\n",
        "a1 = (F.softmax(model(train_ds[i][0].unsqueeze(0).to(device))))\n",
        "\n",
        "t = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Grayscale(3),\n",
        "#     transforms.ColorJitter(10,10, 10),\n",
        "#     transforms.RandomRotation(90),\n",
        "    transforms.ToTensor(),\n",
        "    \n",
        "    ])(train_ds[i][0])\n",
        "a2 = (F.softmax(model(t.unsqueeze(0).to(device))))\n",
        "\n",
        "a3 = (F.softmax(model(((train_ds[i+1][0])).to(device).unsqueeze(0))))\n",
        "\n",
        "\n",
        "print(torch.norm(a1-a2, p = 2))\n",
        "print(torch.norm(a1-a3, p = 2))\n",
        "print(torch.norm(a2-a3, p = 2))\n",
        "model.toggleIntermediate()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}