{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "bert-vision.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfj6qUCzeQfA"
      },
      "source": [
        "## Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMUnskJ9eQfB"
      },
      "source": [
        "storageName = 'university'\n",
        "\n",
        "if storageName == 'paperspace': \n",
        "    guy_folder = \"/notebooks/\"\n",
        "elif storageName == 'colab':\n",
        "    guy_folder = \"/content/\"\n",
        "elif storageName == 'university':\n",
        "    guy_folder = '/vol/scratch/guy/'\n",
        "    \n",
        "    \n",
        "cache_dir = guy_folder+\"/cache/transformer_cache\""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3z5yhLLlzFk"
      },
      "source": [
        "%pip uninstall -y enum34"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqAi8nT2eQfG",
        "outputId": "d037e9cb-428a-49d6-db5e-624ebda582d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# %pip install matplotlib seaborn pandas tqdm tensorboard\n",
        "\n",
        "%cd {guy_folder}\n",
        "!mkdir cache\n",
        "!mkdir cache/transformer_cache\n",
        "# %pip install --no-cache-dir --upgrade torch torchvision\n",
        "#==1.4.0+cu100 torchvision== -f https://download.pytorch.org/whl/torch_stable.html\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htC1bYBQfkz6",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "58de57bb-0f45-479a-e3fe-041a74f45da1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%pip install wandb\n",
        "%cd {guy_folder}/cache/\n",
        "!git clone https://github.com/huggingface/transformers.git\n",
        "%pip install ./transformers\n",
        "%pip install -U nlp\n",
        "\n",
        "%cd {guy_folder}\n",
        "\n",
        "## Not working!!!\n",
        "!setenv TRANSFORMERS_CACHE /vol/scratch/guy/cache/transformer_cache\n",
        "!setenv CUDA_VISIBLE_DEVICES 0"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wandb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2e/d2/f864e4fea30223a694b1454fbe8634eab70d409b5185ec56914bae04d1e8/wandb-0.10.2-py2.py3-none-any.whl (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 3.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from wandb) (3.13)\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/4b/6b/01baa293090240cf0562cc5eccb69c6f5006282127f2b846fad011305c79/configparser-5.0.0-py3-none-any.whl\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.23.0)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n",
            "Collecting sentry-sdk>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/0f/fabe13834484d499064198f8ecf6904a4ce569246ce41d2d747432a8f3c8/sentry_sdk-0.17.8-py2.py3-none-any.whl (120kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 53.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (7.1.2)\n",
            "Collecting GitPython>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/bc/ae32e07e89cc25b9e5c793d19a1e5454d30a8e37d95040991160f942519e/GitPython-3.1.8-py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 27.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (1.15.0)\n",
            "Collecting watchdog>=0.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/06/121302598a4fc01aca942d937f4a2c33430b7181137b35758913a8db10ad/watchdog-0.10.3.tar.gz (94kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 13.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (3.12.4)\n",
            "Collecting subprocess32>=3.5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 14.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (5.4.8)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.8.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.0.0->wandb) (2020.6.20)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/11/d1800bca0a3bae820b84b7d813ad1eff15a48a64caea9c823fc8c1b119e8/gitdb-4.0.5-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 11.1MB/s \n",
            "\u001b[?25hCollecting pathtools>=0.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.12.0->wandb) (50.3.0)\n",
            "Collecting smmap<4,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/b0/9a/4d409a6234eb940e6a78dfdfc66156e7522262f5f2fecca07dc55915952d/smmap-3.0.4-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: watchdog, subprocess32, pathtools\n",
            "  Building wheel for watchdog (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for watchdog: filename=watchdog-0.10.3-cp36-none-any.whl size=73873 sha256=1d552432e5c9ff7483999e8dc4e2b28cc0ed6144f70a35deb8902eb2a3aa900e\n",
            "  Stored in directory: /root/.cache/pip/wheels/a8/1d/38/2c19bb311f67cc7b4d07a2ec5ea36ab1a0a0ea50db994a5bc7\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp36-none-any.whl size=6489 sha256=9259f0c060e30ad333d3207c5ee7f7e6f07174261f964d0225d54e8aca9bf400\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-cp36-none-any.whl size=8785 sha256=2bda1e1c024f683b0f087b699192770ab6941a010b3eb6d0f63c26d476246776\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
            "Successfully built watchdog subprocess32 pathtools\n",
            "Installing collected packages: configparser, shortuuid, sentry-sdk, smmap, gitdb, GitPython, pathtools, watchdog, subprocess32, docker-pycreds, wandb\n",
            "Successfully installed GitPython-3.1.8 configparser-5.0.0 docker-pycreds-0.4.0 gitdb-4.0.5 pathtools-0.1.2 sentry-sdk-0.17.8 shortuuid-1.0.1 smmap-3.0.4 subprocess32-3.5.4 wandb-0.10.2 watchdog-0.10.3\n",
            "/content/cache\n",
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 27, done.\u001b[K\n",
            "remote: Counting objects: 100% (27/27), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 43999 (delta 8), reused 2 (delta 0), pack-reused 43972\u001b[K\n",
            "Receiving objects: 100% (43999/43999), 31.69 MiB | 27.45 MiB/s, done.\n",
            "Resolving deltas: 100% (30506/30506), done.\n",
            "Processing ./transformers\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==3.2.0) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==3.2.0) (2.23.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==3.2.0) (0.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==3.2.0) (1.18.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==3.2.0) (2019.12.20)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 5.6MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.8.1.rc2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/83/8b9fccb9e48eeb575ee19179e2bdde0ee9a1904f97de5f02d19016b8804f/tokenizers-0.8.1rc2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 31.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==3.2.0) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==3.2.0) (20.4)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 53.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.2.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.2.0) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.2.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.2.0) (1.24.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.2.0) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.2.0) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.2.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.2.0) (0.16.0)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-3.2.0-cp36-none-any.whl size=1059218 sha256=cebc9e541b7a8bb60f1891db29b2bf0f4523f2b6e935aa490ed4af6c05e8153f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-k7vu245x/wheels/02/9b/9d/6253b37fb4f7d72b5eeaacbbc3116710b11f600803e913a13f\n",
            "Successfully built transformers\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=4bc1ce0fa0fce0beabbaee872879af413a0b469a06300efcf475cd3455ea2902\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc2 transformers-3.2.0\n",
            "Collecting nlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/e3/bcdc59f3434b224040c1047769c47b82705feca2b89ebbc28311e3764782/nlp-0.4.0-py3-none-any.whl (1.7MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7MB 4.6MB/s \n",
            "\u001b[?25hCollecting pyarrow>=0.16.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/99/0a605f016121ca314d1469dc9069e4978395bc46fda40f73099d90ad3ba4/pyarrow-1.0.1-cp36-cp36m-manylinux2014_x86_64.whl (17.3MB)\n",
            "\u001b[K     |████████████████████████████████| 17.3MB 204kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from nlp) (0.7)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from nlp) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from nlp) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.6/dist-packages (from nlp) (3.0.12)\n",
            "Requirement already satisfied, skipping upgrade: dill in /usr/local/lib/python3.6/dist-packages (from nlp) (0.3.2)\n",
            "Collecting xxhash\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/73/826b19f3594756cb1c6c23d2fbd8ca6a77a9cd3b650c9dec5acc85004c38/xxhash-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (242kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 54.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.6/dist-packages (from nlp) (1.0.5)\n",
            "Requirement already satisfied, skipping upgrade: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from nlp) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->nlp) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->nlp) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->nlp) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->nlp) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->nlp) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->nlp) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas->nlp) (1.15.0)\n",
            "Installing collected packages: pyarrow, xxhash, nlp\n",
            "  Found existing installation: pyarrow 0.14.1\n",
            "    Uninstalling pyarrow-0.14.1:\n",
            "      Successfully uninstalled pyarrow-0.14.1\n",
            "Successfully installed nlp-0.4.0 pyarrow-1.0.1 xxhash-2.0.0\n",
            "/content\n",
            "/bin/bash: setenv: command not found\n",
            "/bin/bash: setenv: command not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KPmqdmNj6dN"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhRzzS1eeQfZ",
        "outputId": "96625f55-6e5d-4795-c812-f67d6e06a94f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets import ImageNet, ImageFolder, CIFAR10, CIFAR100\n",
        "from torchvision import transforms\n",
        "from torchvision.models import resnet101\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from transformers import AdamW\n",
        "import wandb"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wks3jN_niRZ7"
      },
      "source": [
        "# Sweep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5RPTY5Ww0Fq"
      },
      "source": [
        "from getpass import getpass\n",
        "!wandb login {getpass()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mo6pVi-alzI9",
        "outputId": "4ab0e4dd-6c4d-489d-f9bd-d9f463aa5a0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "%%writefile bert-vision.py\n",
        "\n",
        "storageName = 'colab'\n",
        "\n",
        "if storageName == 'paperspace': \n",
        "    guy_folder = \"/notebooks/\"\n",
        "elif storageName == 'colab':\n",
        "    guy_folder = \"/content/\"\n",
        "elif storageName == 'university':\n",
        "    guy_folder = '/vol/scratch/guy/'\n",
        "\n",
        "    \n",
        "cache_dir = guy_folder + \"/cache/transformer_cache\"\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets import ImageNet, ImageFolder, CIFAR10, CIFAR100\n",
        "from torchvision import transforms\n",
        "from torchvision.models import resnet101, resnet50\n",
        "from transformers import AutoModel, AutoTokenizer, AutoConfig\n",
        "from transformers import AdamW\n",
        "import wandb\n",
        "import os.path\n",
        "\n",
        "assert(os.path.isdir(cache_dir))\n",
        "\n",
        "\n",
        "class DummyLayer(nn.Module):\n",
        "  def __init__(self, *args, **kwargs):\n",
        "    super().__init__()\n",
        "    pass\n",
        "  def forward(self, x, *args, **kwargs):\n",
        "    return x\n",
        "\n",
        "class PlainBERT(nn.Module):\n",
        "    def __init__(self, n_tokens, min_layer = None, pretrained = True):\n",
        "        super().__init__()\n",
        "        self.nLayers = 6\n",
        "        self.nHeads = 12\n",
        "        self.seqLen = 512\n",
        "\n",
        "        modelName = 'distilbert-base-uncased'\n",
        "        if pretrained:\n",
        "          bert = AutoModel.from_pretrained(modelName, cache_dir = cache_dir)\n",
        "        else:\n",
        "          bertConfig = AutoConfig.from_pretrained(modelName, cache_dir = cache_dir)\n",
        "          bert = AutoModel.from_config(bertConfig)\n",
        "\n",
        "        self.position_embeddings = nn.Parameter(\n",
        "            torch.Tensor(bert.embeddings.position_embeddings(torch.arange(self.seqLen)).detach().numpy()))\n",
        "        if min_layer is None:\n",
        "          self.bert = bert.transformer\n",
        "        else:\n",
        "          raise NotImplementedError\n",
        "          bert_ = bert.transformer\n",
        "          for n, m in bert_.layer.named_children():\n",
        "            if int(n) < min_layer:\n",
        "              setattr(bert_.layer, n, DummyLayer())\n",
        "        \n",
        "          self.bert = bert_\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.bert.forward(x + self.position_embeddings, attn_mask = torch.ones(x.size(0), 512).to(x.device),\n",
        "                                head_mask = torch.ones(self.nLayers, x.size(0), \n",
        "                                                       self.nHeads, self.seqLen, self.seqLen).to(x.device))\n",
        "\n",
        "class BertVision(nn.Module):\n",
        "    def __init__(self,  n_classes, img_dim, pretrained = True,\n",
        "                 freeze = False):\n",
        "        super().__init__()\n",
        "        self.with_classifier = True\n",
        "        self.n_tokens = np.prod(img_dim)\n",
        "        self.top = nn.Sequential(\n",
        "                                 nn.Conv2d(3, 32, 3, padding = 1 ),\n",
        "                                 nn.LeakyReLU(0.2),\n",
        "                                 nn.Conv2d(32, 100, 3, padding = 1),\n",
        "                                 nn.LeakyReLU(0.2),\n",
        "                                 nn.Conv2d(100, 200, 3, padding = 1),\n",
        "                                 nn.LeakyReLU(0.2),\n",
        "                                 nn.Conv2d(200, 768, 3, stride = (1, 2), padding = 1),\n",
        "                                 nn.LeakyReLU(0.2)\n",
        "                                )\n",
        "        \n",
        "        self.top.apply(self._init_top)\n",
        "        self.bert = PlainBERT(n_tokens = self.n_tokens, pretrained = pretrained)\n",
        "        self.fc = nn.Linear(768 * self.n_tokens//2, n_classes)\n",
        "        self.layer_norm = nn.LayerNorm((512,))\n",
        "        if freeze: \n",
        "          self.bert.requires_grad_(False)\n",
        "\n",
        "    def toggleIntermediate(self):\n",
        "        self.with_classifier = not self.with_classifier\n",
        "    \n",
        "    \n",
        "    def _init_top(self, m):\n",
        "        if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
        "            nn.init.kaiming_uniform_(m.weight)\n",
        "            m.bias.data.fill_(0.01)\n",
        "        pass\n",
        "    def forward(self, x):\n",
        "        x = self.top(x)\n",
        "        x = x.view(x.size(0), x.size(1), -1)\n",
        "        x = x.transpose(1,2)\n",
        "        x = self.bert(x)\n",
        "        x = torch.stack(x).squeeze(0)\n",
        "        x = x.transpose(1,2).contiguous()\n",
        "#         x = self.layer_norm(x)\n",
        "#         x = torch.mean(x, dim = (-2,))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        if self.with_classifier:\n",
        "            x = self.fc(x)\n",
        "        return x.squeeze(1)\n",
        "    \n",
        "    \n",
        "    \n",
        "device = 'cuda'\n",
        "train_ds = CIFAR100(\"{}/data/cifar100\".format(guy_folder), download = True, transform=transforms.ToTensor())\n",
        "test_ds = CIFAR100(\"{}/data/cifar100\".format(guy_folder), download = True, transform=transforms.ToTensor(), train = False)\n",
        "\n",
        "\n",
        "batch_size = 8\n",
        "\n",
        "lr = {'bert-vision': [1e-6, 5e-6, 1e-5, 5e-5],\n",
        "      'resnet': [3e-4, 1e-3, 3e-3, 1e-2]\n",
        "      }\n",
        "\n",
        "optimizerDict = {'adam': torch.optim.Adam,\n",
        "                 'adamw': AdamW,\n",
        "                 'sgd': torch.optim.SGD, # No momentum\n",
        "                 }\n",
        "\n",
        "def makeModel(modelName, pretrained, freeze):\n",
        "  if modelName == 'resnet':\n",
        "    model_resnet = resnet50(pretrained = pretrained)\n",
        "    if freeze:\n",
        "      model_resnet.requires_grad_(False)\n",
        "    model_resnet.fc = nn.Linear(model_resnet.fc.in_features, 100)\n",
        "    model_resnet.to(device)\n",
        "    model = model_resnet\n",
        "  elif modelName == 'bert-vision':\n",
        "    model = BertVision(len(train_ds.classes), (32,32), pretrained = pretrained,\n",
        "                       freeze = freeze).to(device)\n",
        "  else:\n",
        "    model = Sequential()\n",
        "  return model\n",
        "\n",
        "def _convertBool(s):\n",
        "  s = s.lower()\n",
        "  assert(s in ['true', 'false'])\n",
        "  return s == 'true'\n",
        "\n",
        "\n",
        "def train(config):\n",
        "  \n",
        "  optimizerAlg = optimizerDict[config.optimizer]\n",
        "  if config.model == 'bert-vision': \n",
        "    if config.optimizer == 'adam':\n",
        "      optimizerAlg = optimizerDict['adamw']\n",
        "    if config.optimizer == 'sgd':\n",
        "      return\n",
        "    \n",
        "\n",
        "  modelName = config.model\n",
        "  lr_idx = config.lr_idx\n",
        "  pretrained = _convertBool(config.pretrained)\n",
        "  freeze = _convertBool(config.freeze)\n",
        "  model = makeModel(modelName, pretrained = pretrained, freeze = freeze)\n",
        "\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = optimizerAlg(model.parameters(), lr = lr[modelName][lr_idx])\n",
        "  train_dataloader = DataLoader(train_ds, batch_size = batch_size, shuffle = True)\n",
        "  test_dataloader = DataLoader(test_ds, batch_size = batch_size, shuffle = True)\n",
        "  pbar = tqdm(train_dataloader, leave = True, position = 0)\n",
        "  acc_sum = 0\n",
        "\n",
        "  for i, (x,y) in enumerate(pbar):\n",
        "      model.train()    \n",
        "      optimizer.zero_grad()\n",
        "      y = y.to(device)\n",
        "      yhat = model(x.to(device))\n",
        "      loss = criterion(yhat, y)\n",
        "      acc_sum += (yhat.argmax(dim =  -1) == y).sum()    \n",
        "      wandb.log({'loss': loss.item(), \n",
        "                 'acc': acc_sum.item() / (batch_size * (i+1))})\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "wandb.init(project = 'bert-vision')\n",
        "\n",
        "from argparse import ArgumentParser\n",
        "parser = ArgumentParser()\n",
        "parser.add_argument('--lr_idx', type=int, default=0, metavar='N')\n",
        "parser.add_argument('--optimizer', type=str, default='adam', metavar='N')\n",
        "parser.add_argument('--pretrained', type=str, default='true', metavar='N')\n",
        "parser.add_argument('--model', type=str, default='bert-vision', metavar='N')\n",
        "parser.add_argument('--freeze', type=str, default='false', metavar='N')\n",
        "\n",
        "args = parser.parse_args()\n",
        "wandb.config.update(args)\n",
        "\n",
        "config = wandb.config\n",
        "train(config)\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting bert-vision.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJA22phbj1S6"
      },
      "source": [
        "config = {\n",
        "    'method': 'grid',\n",
        "    'program': 'bert-vision.py',\n",
        "    'parameters': \n",
        "    {\n",
        "        'lr_idx': {'values': [0, 1, 2, 3]},\n",
        "        'optimizer':{'values': ['adam', 'sgd']},\n",
        "        'model': {'values': ['resnet', 'bert-vision']},\n",
        "        'pretrained': [True, False]\n",
        "    }\n",
        "}\n",
        "sweep_id = wandb.sweep(config, project = 'bert-vision')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwZwLpMFyeNE",
        "outputId": "3971822a-3b5f-4df6-b188-5e4a3d5e6eaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 840
        }
      },
      "source": [
        "!python bert-vision.py --lr_idx=1 --model=bert-vision --optimizer=adam --pretrained=false"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-09-28 08:58:14.540752: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdar-tau\u001b[0m (use `wandb login --relogin` to force relogin)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20200928_085818-jm74gsr1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mclassic-sun-75\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/dar-tau/bert-vision\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/dar-tau/bert-vision/runs/jm74gsr1\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
            "\n",
            "Downloading: 100%|██████████| 442/442 [00:00<00:00, 285kB/s]\n",
            "  0%|          | 0/6250 [00:00<?, ?it/s][W TensorIterator.cpp:918] Warning: Mixed memory format inputs detected while calling the operator. The operator will output contiguous tensor even if some of the inputs are in channels_last format. (function operator())\n",
            " 64%|██████▎   | 3975/6250 [38:25<22:02,  1.72it/s]Traceback (most recent call last):\n",
            "  File \"bert-vision.py\", line 197, in <module>\n",
            "    train(config)\n",
            "  File \"bert-vision.py\", line 175, in train\n",
            "    yhat = model(x.to(device))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 722, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"bert-vision.py\", line 110, in forward\n",
            "    x = self.bert(x)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 722, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"bert-vision.py\", line 74, in forward\n",
            "    self.nHeads, self.seqLen, self.seqLen).to(x.device))\n",
            "KeyboardInterrupt\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 787\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Program failed with code 255.  Press ctrl-c to abort syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20200928_085818-jm74gsr1/logs/debug.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20200928_085818-jm74gsr1/logs/debug-internal.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         loss 3.7537965774536133\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          acc 0.12047169811320754\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        _step 3974\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     _runtime 2313\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   _timestamp 1601285811\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         loss ▆▇▆▄▆▆▇▆▅▄▆▆▅▄▆▇▅▄▄▆▅▄▂▄▁▄▂▄█▄▆▂▂▄▅▅▄▆▂▅\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          acc ▁▂▂▂▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇██████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        _step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     _runtime ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   _timestamp ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mclassic-sun-75\u001b[0m: \u001b[34mhttps://wandb.ai/dar-tau/bert-vision/runs/jm74gsr1\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fU3OwHktlzJR"
      },
      "source": [
        "assert(sweep_id.isalnum())\n",
        "!wandb agent {sweep_id}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMj5CiiIlzJc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oT_5ShNJmBcx"
      },
      "source": [
        "# Experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sS-kATGqeQfc"
      },
      "source": [
        "\n",
        "class DummyLayer(nn.Module):\n",
        "  def __init__(self, *args, **kwargs):\n",
        "    super().__init__()\n",
        "    pass\n",
        "  def forward(self, x, *args, **kwargs):\n",
        "    return x\n",
        "\n",
        "class PlainBERT(nn.Module):\n",
        "    def __init__(self, n_tokens, min_layer = None):\n",
        "        super().__init__()\n",
        "        self.nLayers = 6\n",
        "        self.nHeads = 12\n",
        "        self.seqLen = 512\n",
        "\n",
        "\n",
        "        bert = AutoModel.from_pretrained('distilbert-base-uncased', cache_dir = cache_dir)\n",
        "        self.position_embeddings = nn.Parameter(torch.Tensor(bert.embeddings.position_embeddings(torch.arange(self.seqLen)).detach().numpy()))\n",
        "        if min_layer is None:\n",
        "          self.bert = bert.transformer\n",
        "        else:\n",
        "          raise NotImplementedError\n",
        "          bert_ = bert.transformer\n",
        "          for n, m in bert_.layer.named_children():\n",
        "            if int(n) < min_layer:\n",
        "              setattr(bert_.layer, n, DummyLayer())\n",
        "        \n",
        "          self.bert = bert_\n",
        "        self.bert.requires_grad_(False)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.bert.forward(x + self.position_embeddings, attn_mask = torch.ones(x.size(0), 512).to(x.device),\n",
        "                                head_mask = torch.ones(self.nLayers, x.size(0), self.nHeads, self.seqLen, self.seqLen).to(x.device))\n",
        "\n",
        "class BertVision(nn.Module):\n",
        "    def __init__(self,  n_classes, img_dim):\n",
        "        super().__init__()\n",
        "        self.with_classifier = True\n",
        "        self.n_tokens = np.prod(img_dim)\n",
        "        self.top = nn.Sequential(\n",
        "                                 nn.Conv2d(3, 32, 3, padding = 1 ),\n",
        "                                 nn.LeakyReLU(0.2),\n",
        "                                 nn.Conv2d(32, 100, 3, padding = 1),\n",
        "                                 nn.LeakyReLU(0.2),\n",
        "                                 nn.Conv2d(100, 200, 3, padding = 1),\n",
        "                                 nn.LeakyReLU(0.2),\n",
        "                                 nn.Conv2d(200, 768, 3, stride = (1, 2), padding = 1),\n",
        "                                 nn.LeakyReLU(0.2)\n",
        "                                )\n",
        "        \n",
        "        self.top.apply(self._init_top)\n",
        "        self.bert = PlainBERT(n_tokens = self.n_tokens)\n",
        "        self.fc = nn.Linear(768 * self.n_tokens//2, n_classes)\n",
        "        self.layer_norm = nn.LayerNorm((512,))\n",
        "\n",
        "    def toggleIntermediate(self):\n",
        "        self.with_classifier = !self.with_classifier\n",
        "    \n",
        "    \n",
        "    def _init_top(self, m):\n",
        "        if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
        "            nn.init.kaiming_uniform_(m.weight)\n",
        "            m.bias.data.fill_(0.01)\n",
        "        pass\n",
        "    def forward(self, x):\n",
        "        x = self.top(x)\n",
        "        x = x.view(x.size(0), x.size(1), -1)\n",
        "        x = x.transpose(1,2)\n",
        "        x = self.bert(x)\n",
        "        x = torch.stack(x).squeeze(0)\n",
        "        x = x.transpose(1,2).contiguous()\n",
        "#         x = self.layer_norm(x)\n",
        "#         x = torch.mean(x, dim = (-2,))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        if self.with_classifier:\n",
        "            x = self.fc(x)\n",
        "        return x.squeeze(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Udifw4deQfn",
        "outputId": "e7c6ea1a-d948-41e3-f421-b3d6822a3483"
      },
      "source": [
        "device = 'cuda'\n",
        "train_ds = CIFAR100(\"{}/data/cifar100\".format(guy_folder), download = True, transform=transforms.ToTensor())\n",
        "test_ds = CIFAR100(\"{}/data/cifar100\".format(guy_folder), download = True, transform=transforms.ToTensor(), train = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to /notebooks//data/cifar100/cifar-100-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "169009152it [00:09, 18300545.88it/s]                               \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /notebooks//data/cifar100/cifar-100-python.tar.gz to /notebooks//data/cifar100\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ixPIuePqq86"
      },
      "source": [
        "%%script false\n",
        "# After login in through firefox to ImageNet\n",
        "%cd {guy_folder}/data\n",
        "!wget http://www.image-net.org/archive/stanford/fall11_whole.tar\n",
        "# !tar -xvf "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnJGD7m7qfSw"
      },
      "source": [
        "%%script false\n",
        "train_folder = \"{}/data/imagenet12/train\".format(guy_folder)\n",
        "\n",
        "train_ds = ImageFolder(train_folder,\n",
        "            transform = transforms.Compose([transforms.ToTensor()]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3MFYU_SeQfx"
      },
      "source": [
        "from collections import defaultdict\n",
        "batch_size = 8\n",
        "total = int(len(train_ds)/batch_size )\n",
        "\n",
        "from tqdm import tqdm_notebook, tqdm\n",
        "class_rep = defaultdict(int)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr = 1e-6)\n",
        "train_dataloader = DataLoader(train_ds, batch_size = batch_size, shuffle = True)\n",
        "test_dataloader = DataLoader(test_ds, batch_size = batch_size, shuffle = True)\n",
        "pbar = tqdm(enumerate(train_dataloader), total = total, leave = True, position = 0)\n",
        "acc_sum = 0\n",
        "\n",
        "for i, (x,y) in pbar:\n",
        "    if i >= total:\n",
        "        break\n",
        "    model.eval()\n",
        "    x_test, y_test = next(iter(test_dataloader))\n",
        "    test_acc = ((model(x_test.to(device)).argmax(dim =  -1) == y_test.to(device)).sum()).item()/batch_size\n",
        "    model.train()\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    y = y.to(device)\n",
        "    yhat = model(x.to(device))\n",
        "    loss = criterion(yhat, y)\n",
        "    acc_sum += (yhat.argmax(dim =  -1) == y).sum()\n",
        "    class_rep[y[0].item()] += 1 # Incomplete\n",
        "    topk = np.where(np.argsort(yhat[0].cpu().detach().numpy()) == y[0].detach().cpu().numpy())[0][0] # TODO: Incomplete\n",
        "    \n",
        "    pbar.set_postfix_str(\"Loss: {:.2f} Test Acc: {:.2f} Acc: {:.2f} Top: {} Class: {}\".format(loss.item(),\n",
        "                                                                                               test_acc, \n",
        "                                                                             acc_sum.item()/float(batch_size * (i+1)), \n",
        "                                                                             topk, class_rep[y[0].item()]))\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ul5_1EQo4ynl",
        "outputId": "6d8957e3-3276-4c16-9cd4-e8bc8a7c58f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "from collections import defaultdict\n",
        "batch_size = 32\n",
        "total = int(len(train_ds)/batch_size )\n",
        "\n",
        "from tqdm import tqdm_notebook, tqdm\n",
        "class_rep = defaultdict(int)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(vision_model.parameters(), lr = 1e-2)\n",
        "train_dataloader = DataLoader(train_ds, batch_size = batch_size, shuffle = True)\n",
        "pbar = tqdm(enumerate(train_dataloader), total = total, leave = True, position = 0)\n",
        "acc_sum = 0\n",
        "\n",
        "for i, (x,y) in pbar:\n",
        "    if i >= total:\n",
        "        break\n",
        "    optimizer.zero_grad()\n",
        "    y = y.to(device)\n",
        "    # x = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "    #         std=[0.229, 0.224, 0.225],)(x)\n",
        "    yhat = vision_model(x.to(device))\n",
        "    loss = criterion(yhat, y)\n",
        "    acc_sum += (yhat.argmax(dim =  -1) == y).sum()\n",
        "    class_rep[y[0].item()] += 1 # Incomplete\n",
        "    topk = np.where(np.argsort(yhat[0].cpu().detach().numpy()) == y[0].detach().cpu().numpy())[0][0] # TODO: Incomplete\n",
        "    pbar.set_postfix_str(\"Loss: {:.2f} Acc: {:.2f} Top: {} Class: {}\".format(loss.item(), \n",
        "                                                                            acc_sum.item()/float(batch_size * (i+1)), \n",
        "                                                                            topk, class_rep[y[0].item()]))\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 1561/1562 [02:02<00:00, 12.76it/s, Loss: 3.81 Acc: 0.07 Top: 93 Class: 12]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iOzYWVLeQf1"
      },
      "source": [
        "y  = []\n",
        "z = []\n",
        "for x, _  in tqdm(train_ds):\n",
        "    z.append(x)\n",
        "    y.append((model(x.to(device).unsqueeze(0))).detach())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-3XJcm1eQf5"
      },
      "source": [
        "y = torch.stack(y)\n",
        "z = torch.stack(z)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FqeYGjteQf9",
        "outputId": "825df2ce-a86d-427c-cbf8-afe92780eddb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "z.std()/y.std()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1882, device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQ5EySnveQgC"
      },
      "source": [
        "i = np.random.choice(len(train_ds))\n",
        "print(F.softmax(model(train_ds[i][0].unsqueeze(0).to(device))))\n",
        "print(model(train_ds[i][0].unsqueeze(0).to(device)).argmax())\n",
        "print(train_ds[i][1])\n",
        "t = transforms.Compose([\n",
        "#     transforms.Grayscale(),\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Grayscale(3),\n",
        "    transforms.ToTensor(),\n",
        "    \n",
        "    ])(train_ds[i][0])\n",
        "print(F.softmax(model(t.unsqueeze(0).to(device))))\n",
        "print(model(t.unsqueeze(0).to(device)).argmax())\n",
        "\n",
        "print(F.softmax(model(((train_ds[i+1][0])).unsqueeze(0).to(device))))\n",
        "print(F.softmax(model(((train_ds[i+1][0])).unsqueeze(0).to(device))).argmax())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncJnwGykeQgH"
      },
      "source": [
        "model.load_state_dict(state_dict,strict = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPjRCbmAeQgL"
      },
      "source": [
        "model.toggleIntermediate()\n",
        "i = np.random.choice(len(train_ds))\n",
        "a1 = (F.softmax(model(train_ds[i][0].unsqueeze(0).to(device))))\n",
        "\n",
        "t = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Grayscale(3),\n",
        "#     transforms.ColorJitter(10,10, 10),\n",
        "#     transforms.RandomRotation(90),\n",
        "    transforms.ToTensor(),\n",
        "    \n",
        "    ])(train_ds[i][0])\n",
        "a2 = (F.softmax(model(t.unsqueeze(0).to(device))))\n",
        "\n",
        "a3 = (F.softmax(model(((train_ds[i+1][0])).to(device).unsqueeze(0))))\n",
        "\n",
        "\n",
        "print(torch.norm(a1-a2, p = 2))\n",
        "print(torch.norm(a1-a3, p = 2))\n",
        "print(torch.norm(a2-a3, p = 2))\n",
        "model.toggleIntermediate()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}